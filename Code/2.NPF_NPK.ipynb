{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "X80IWiSh3qv1"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#CIFAR-10"
      ],
      "metadata": {
        "id": "MwAXeXRfmUDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imports**"
      ],
      "metadata": {
        "id": "s5uHxozAThHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "random.seed(365)"
      ],
      "metadata": {
        "id": "68R3vBfmTplP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Device configuration**"
      ],
      "metadata": {
        "id": "ZbdR0o4fTsvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "gbqIt7wvTyxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CONV4"
      ],
      "metadata": {
        "id": "yKceqp76nEm9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyper-parameters**"
      ],
      "metadata": {
        "id": "1aI836QqT3Dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-parameters \n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "learning_rate = 0.0003 #0.01\n",
        "beta = 10\n",
        "optimizer_name = 'Adam'"
      ],
      "metadata": {
        "id": "2-4L5AZAT-c1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DNN"
      ],
      "metadata": {
        "id": "_lvlfPHHoylM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Building**"
      ],
      "metadata": {
        "id": "4etxfcLkUScy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 64, 3)\n",
        "    self.conv2 = nn.Conv2d(64, 64, 3)\n",
        "    self.conv3 = nn.Conv2d(64, 128, 3)\n",
        "    self.conv4 = nn.Conv2d(128, 128, 3)\n",
        "    # self.gap = nn.AvgPool2d(24)\n",
        "    self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc1 = nn.Linear(128 * 1 * 1, 256)\n",
        "    self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "  def forward(self, x,beta):\n",
        "    # -> n, 3, 32, 32\n",
        "    x = F.relu(self.conv1(x))  # -> n, 64, 30, 30\n",
        "    # print(x.shape)\n",
        "    x = F.relu(self.conv2(x))  # -> n, 64, 28, 28\n",
        "    # print(x.shape)\n",
        "    x = F.relu(self.conv3(x))  # -> n, 128, 26, 26\n",
        "    # print(x.shape)\n",
        "    x = F.relu(self.conv4(x))  # -> n, 128, 24, 24\n",
        "    # print(x.shape)\n",
        "    x = self.gap(x)           # -> n, 128, 1, 1\n",
        "    # print(x.shape)\n",
        "\n",
        "    x = x.view(-1, 128 * 1 * 1)            # -> n, 128 * 1 * 1\n",
        "    x = self.fc1(x)               # -> n, 256\n",
        "    x = F.relu(x)\n",
        "    x = self.fc2(x)                       # -> n, 10\n",
        "    return x\n",
        "\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if optimizer_name == 'SGD':\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "if optimizer_name == 'Adam':\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
      ],
      "metadata": {
        "id": "i73di1BNUV2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DGN"
      ],
      "metadata": {
        "id": "5OjdzTzXb60f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "    self.conv1_gt = nn.Conv2d(3, 64, 3)\n",
        "    self.conv2_gt = nn.Conv2d(64, 64, 3)\n",
        "    self.conv3_gt = nn.Conv2d(64, 128, 3)\n",
        "    self.conv4_gt = nn.Conv2d(128, 128, 3)\n",
        "\n",
        "    self.conv1_wt = nn.Conv2d(3, 64, 3)\n",
        "    self.conv2_wt = nn.Conv2d(64, 64, 3)\n",
        "    self.conv3_wt = nn.Conv2d(64, 128, 3)\n",
        "    self.conv4_wt = nn.Conv2d(128, 128, 3)\n",
        "    self.galu = nn.Sigmoid()\n",
        "    # self.gap = nn.AvgPool2d(24)\n",
        "    self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc1 = nn.Linear(128 * 1 * 1, 256)\n",
        "    self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "  def forward(self, x, beta):\n",
        "    x_wt=x  #x_wt = x is the input for bottom weight network\n",
        "\n",
        "    # print(\"Initial weights\")\n",
        "    # print(self.conv1.weight)\n",
        "    # print(self.conv1.weight.shape)\n",
        "    # print(\"Initial biases\")\n",
        "    # print(self.conv1.bias)\n",
        "    # print(self.conv1.bias.shape)\n",
        "    ## 1st Block\n",
        "    x_gt=self.conv1_gt(x)   #x_gt is for top gate network\n",
        "    # print(\"X_gt\")\n",
        "    # print(x_gt)\n",
        "    # print(x_gt.shape)\n",
        "    g1=self.galu(beta*x_gt)\n",
        "    # print(\"g1\")\n",
        "    # print(g1)\n",
        "    # print(g1.shape)\n",
        "    x_wt=self.conv1_wt(x_wt)\n",
        "    # print(\"X_wt\")\n",
        "    # print(x_wt)\n",
        "    # print(x_wt.shape)\n",
        "    x_wt=g1*x_wt\n",
        "    # print(\"X_wt\")\n",
        "    # print(x_wt)\n",
        "    # print(x_wt.shape)\n",
        "    x_gt = F.relu(x_gt) \n",
        "    # print(\"X_gt\")\n",
        "    # print(x_gt)\n",
        "    # print(x_gt.shape)\n",
        "    # print(\"====================================================================================================================================\")    \n",
        "    # print(\"====================================================================================================================================\")    \n",
        "    # print(\"====================================================================================================================================\")    \n",
        "    # print(\"====================================================================================================================================\")    \n",
        "    ## 2nd Block\n",
        "    x_gt=self.conv2_gt(x_gt)\n",
        "    g2=self.galu(beta*x_gt)\n",
        "    x_wt=self.conv2_wt(x_wt)\n",
        "    x_wt=g2*x_wt\n",
        "    x_gt = F.relu(x_gt)\n",
        "\n",
        "    ## 3rd Block\n",
        "    x_gt=self.conv3_gt(x_gt)\n",
        "    g3=self.galu(beta*x_gt)\n",
        "    x_wt=self.conv3_wt(x_wt)\n",
        "    x_wt=g3*x_wt\n",
        "    x_gt = F.relu(x_gt) \n",
        "\n",
        "    ## 4th Block\n",
        "    x_gt=self.conv4_gt(x_gt)\n",
        "    g4=self.galu(beta*x_gt)\n",
        "    x_wt=self.conv4_wt(x_wt)\n",
        "    x_wt=g4*x_wt\n",
        "\n",
        "    x_gt = F.relu(x_gt)\n",
        "    x_gt = self.gap(x_gt)\n",
        "    x_gt = x_gt.view(-1, 128 * 1 * 1)           \n",
        "    x_gt = self.fc1(x_gt)              \n",
        "    g5_fc=self.galu(beta*x_gt)\n",
        "\n",
        "    x_wt = self.gap(x_wt)\n",
        "\n",
        "\n",
        "    x_wt = x_wt.view(-1, 128 * 1 * 1)           \n",
        "    x_wt = self.fc1(x_wt) \n",
        "    x_wt=g5_fc*x_wt             \n",
        "    x_wt = self.fc2(x_wt)                     \n",
        "    return x_wt\n",
        "\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if optimizer_name == 'SGD':\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "if optimizer_name == 'Adam':\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
      ],
      "metadata": {
        "id": "dMDpGk6ocCZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DLGN"
      ],
      "metadata": {
        "id": "n2wPsc6M7Nma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "    self.conv1_gt = nn.Conv2d(3, 64, 3)\n",
        "    self.conv2_gt = nn.Conv2d(64, 64, 3)\n",
        "    self.conv3_gt = nn.Conv2d(64, 128, 3)\n",
        "    self.conv4_gt = nn.Conv2d(128, 128, 3)\n",
        "\n",
        "    self.conv1_wt = nn.Conv2d(3, 64, 3)\n",
        "    self.conv2_wt = nn.Conv2d(64, 64, 3)\n",
        "    self.conv3_wt = nn.Conv2d(64, 128, 3)\n",
        "    self.conv4_wt = nn.Conv2d(128, 128, 3)\n",
        "    self.galu = nn.Sigmoid()\n",
        "    # self.gap = nn.AvgPool2d(24)\n",
        "    self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc1 = nn.Linear(128 * 1 * 1, 256)\n",
        "    self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "  def forward(self, x, beta):\n",
        "    import numpy as np\n",
        "\n",
        "    x_wt = np.linspace(1.0, 1.0, 3072*x.shape[0])  #x_wt = 1 is the input for bottom weight network\n",
        "    x_wt= x_wt.reshape(x.shape[0],3,32,32)\n",
        "    x_wt = torch.from_numpy(x_wt).float()\n",
        "    x_wt = x_wt.to(device)\n",
        "\n",
        "    ## 1st Block\n",
        "    x_gt=self.conv1_gt(x)  #x_gt is for top gate network\n",
        "    g1=self.galu(beta*x_gt)\n",
        "    x_wt=self.conv1_wt(x_wt)\n",
        "    x_wt=g1*x_wt\n",
        "    # x = F.relu(x) \n",
        "\n",
        "    ## 2nd Block\n",
        "    x_gt=self.conv2_gt(x_gt)\n",
        "    g2=self.galu(beta*x_gt)\n",
        "    x_wt=self.conv2_wt(x_wt)\n",
        "    x_wt=g2*x_wt\n",
        "    # x = F.relu(x)\n",
        "\n",
        "    ## 3rd Block\n",
        "    x_gt=self.conv3_gt(x_gt)\n",
        "    g3=self.galu(beta*x_gt)\n",
        "    x_wt=self.conv3_wt(x_wt)\n",
        "    x_wt=g3*x_wt\n",
        "    # x = F.relu(x) \n",
        "    \n",
        "    ## 4th Block\n",
        "    x_gt=self.conv4_gt(x_gt)\n",
        "    g4=self.galu(beta*x_gt)\n",
        "    x_wt=self.conv4_wt(x_wt)\n",
        "    x_wt=g4*x_wt\n",
        "\n",
        "    x_gt = self.gap(x_gt)\n",
        "    x_gt = x_gt.view(-1, 128 * 1 * 1)           \n",
        "    x_gt = self.fc1(x_gt)              \n",
        "    g5_fc=self.galu(beta*x_gt)\n",
        "\n",
        "    x_wt = self.gap(x_wt)          \n",
        "\n",
        "    x_wt = x_wt.view(-1, 128 * 1 * 1)           \n",
        "    x_wt = self.fc1(x_wt)\n",
        "    x_wt=g5_fc*x_wt                           \n",
        "    x_wt = self.fc2(x_wt)                     \n",
        "    return x_wt\n",
        "\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if optimizer_name == 'SGD':\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "if optimizer_name == 'Adam':\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
      ],
      "metadata": {
        "id": "8_ajf6Dp7TLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Result SGD"
      ],
      "metadata": {
        "id": "X80IWiSh3qv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SGD\n",
        "-------------\n",
        "DNN\n",
        "----\n",
        "5-->57.13\n",
        "10-->62.74\n",
        "15-->67.74\n",
        "20-->66.9\n",
        "25-->71.95\n",
        "30-->71.03\n",
        "35-->71.59\n",
        "40-->70.33\n",
        "45-->70.46\n",
        "50-->69.34\n",
        "55-->70.8\n",
        "75-->72.21\n",
        "95-->72.54\n",
        "DGN\n",
        "----\n",
        "5-->56.73\n",
        "10-->65.06\n",
        "15-->67.23\n",
        "20-->71.62\n",
        "25-->69.25\n",
        "30-->70.48\n",
        "35-->68.81\n",
        "40-->68.73 \n",
        "45-->70.61\n",
        "50-->71.07\n",
        "55-->70.07\n",
        "75-->72.11\n",
        "92-->72.58\n",
        "DLGN\n",
        "----\n",
        "5-->62\n",
        "10-->66.1\n",
        "15--> 67.28\n",
        "20-->66.36\n",
        "25-->66.14\n",
        "30-->66.45\n",
        "35-->66.11\n",
        "40-->65.3\n",
        "45-->66.92\n",
        "50-->66.81\n",
        "55-->66.81\n",
        "75-->66.33 \n",
        "100-->66.17"
      ],
      "metadata": {
        "id": "z3eV1w7I-5jM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Result Adam"
      ],
      "metadata": {
        "id": "PVnrfMOWTJVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Adam\n",
        "-------------\n",
        "DNN\n",
        "----\n",
        "5--> 54.91\n",
        "10-->61.81\n",
        "15-->\n",
        "20-->69.86\n",
        "25-->\n",
        "30-->74.5\n",
        "35-->75.89\n",
        "40-->77.0\n",
        "45-->77.27\n",
        "50-->78.64\n",
        "55-->77.89\n",
        "60-->78.49\n",
        "62-->79.23\n",
        "64-->79.28\n",
        "65-->79.14\n",
        "66-->79.54\n",
        "69-->79.77\n",
        "70-->78.7\n",
        "75-->78.98\n",
        "80-->78.38\n",
        "\n",
        "DGN\n",
        "----\n",
        "5-->\n",
        "10-->\n",
        "15-->\n",
        "20-->\n",
        "25-->76.65\n",
        "30-->\n",
        "35-->\n",
        "40-->\n",
        "45-->\n",
        "50-->76.69\n",
        "55-->\n",
        "75-->\n",
        "92-->\n",
        "DLGN\n",
        "----\n",
        "5-->\n",
        "10-->\n",
        "15-->\n",
        "20-->\n",
        "25-->72.46\n",
        "30-->\n",
        "35-->73.78\n",
        "40-->\n",
        "45-->73.29\n",
        "50-->\n",
        "55-->\n",
        "75--> \n",
        "100-->"
      ],
      "metadata": {
        "id": "GpdNvm_oTWS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG-16"
      ],
      "metadata": {
        "id": "GiHXtAkhSeVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
        "\n",
        "VGG_types = {\n",
        "    \"VGG11\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
        "    \"VGG13\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
        "    \"VGG16\": [\n",
        "        64,\n",
        "        64,\n",
        "        \"M\",\n",
        "        128,\n",
        "        128,\n",
        "        \"M\",\n",
        "        256,\n",
        "        256,\n",
        "        256,\n",
        "        \"M\",\n",
        "        512,\n",
        "        512,\n",
        "        512,\n",
        "        \"M\",\n",
        "        512,\n",
        "        512,\n",
        "        512,\n",
        "        \"M\",\n",
        "    ],\n",
        "    \"VGG19\": [\n",
        "        64,\n",
        "        64,\n",
        "        \"M\",\n",
        "        128,\n",
        "        128,\n",
        "        \"M\",\n",
        "        256,\n",
        "        256,\n",
        "        256,\n",
        "        256,\n",
        "        \"M\",\n",
        "        512,\n",
        "        512,\n",
        "        512,\n",
        "        512,\n",
        "        \"M\",\n",
        "        512,\n",
        "        512,\n",
        "        512,\n",
        "        512,\n",
        "        \"M\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "\n",
        "class VGG_net(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_classes=1000):\n",
        "        super(VGG_net, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.conv_layers = self.create_conv_layers(VGG_types[\"VGG16\"])\n",
        "\n",
        "        self.fcs = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fcs(x)\n",
        "        return x\n",
        "\n",
        "    def create_conv_layers(self, architecture):\n",
        "        layers = []\n",
        "        in_channels = self.in_channels\n",
        "\n",
        "        for x in architecture:\n",
        "            if type(x) == int:\n",
        "                out_channels = x\n",
        "\n",
        "                layers += [\n",
        "                    nn.Conv2d(\n",
        "                        in_channels=in_channels,\n",
        "                        out_channels=out_channels,\n",
        "                        kernel_size=(3, 3),\n",
        "                        stride=(1, 1),\n",
        "                        padding=(1, 1),\n",
        "                    ),\n",
        "                    nn.BatchNorm2d(x),\n",
        "                    nn.ReLU(),\n",
        "                ]\n",
        "                in_channels = x\n",
        "            elif x == \"M\":\n",
        "                layers += [nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))]\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model = VGG_net(in_channels=3, num_classes=1000).to(device)\n",
        "    print(model)\n",
        "    ## N = 3 (Mini batch size)\n",
        "    # x = torch.randn(3, 3, 224, 224).to(device)\n",
        "    # print(model(x).shape)"
      ],
      "metadata": {
        "id": "tA5t6TOmSkHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VGG-16"
      ],
      "metadata": {
        "id": "tO1KUVqMjrZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-parameters \n",
        "num_epochs = 32\n",
        "batch_size = 128\n",
        "learning_rate = 0.01\n",
        "beta = 10\n",
        "optimizer_name = 'SGD'"
      ],
      "metadata": {
        "id": "U6F8ggkDp0Ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG_Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(VGG_Net, self).__init__()\n",
        "    self.conv11 = nn.Conv2d(3, 64, 3, 1, 1)\n",
        "    self.conv12 = nn.Conv2d(64, 64, 3, 1, 1)\n",
        "\n",
        "    self.conv21 = nn.Conv2d(64, 128, 3, 1, 1)\n",
        "    self.conv22 = nn.Conv2d(128, 128, 3, 1, 1)\n",
        "\n",
        "    self.conv31 = nn.Conv2d(128, 256, 3, 1, 1)\n",
        "    self.conv32 = nn.Conv2d(256, 256, 3, 1, 1)\n",
        "    self.conv33 = nn.Conv2d(256, 256, 3, 1, 1)\n",
        "\n",
        "    self.conv41 = nn.Conv2d(256, 512, 3, 1, 1)\n",
        "    self.conv42 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "    self.conv43 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "\n",
        "    self.conv51 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "    self.conv52 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "    self.conv53 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "\n",
        "    # self.gap = nn.AvgPool2d(24)\n",
        "    self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc1 = nn.Linear(512 * 1 * 1, 4096)\n",
        "    self.fc2 = nn.Linear(4096, 4096)\n",
        "    self.fc3 = nn.Linear(4096, 10)\n",
        "\n",
        "  def forward(self, x,beta):\n",
        "    x = F.relu(self.conv11(x))  \n",
        "    x = F.relu(self.conv12(x))\n",
        "\n",
        "    x = F.relu(self.conv21(x))  \n",
        "    x = F.relu(self.conv22(x))  \n",
        "\n",
        "    x = F.relu(self.conv31(x))  \n",
        "    x = F.relu(self.conv32(x))  \n",
        "    x = F.relu(self.conv33(x)) \n",
        "\n",
        "    x = F.relu(self.conv41(x))  \n",
        "    x = F.relu(self.conv42(x))  \n",
        "    x = F.relu(self.conv43(x)) \n",
        "\n",
        "    x = F.relu(self.conv51(x))  \n",
        "    x = F.relu(self.conv52(x))  \n",
        "    x = F.relu(self.conv53(x))  \n",
        "    x = self.gap(x)           \n",
        "\n",
        "    x = x.view(-1, 512 * 1 * 1)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc3(x)     \n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "model = VGG_Net().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if optimizer_name == 'SGD':\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum= 0.9)\n",
        "if optimizer_name == 'Adam':\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
      ],
      "metadata": {
        "id": "KuQx8HmfjwKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloading, Training and Testing"
      ],
      "metadata": {
        "id": "zsV_1AaYV-gw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Preparation & Loading**"
      ],
      "metadata": {
        "id": "s6crXN08UGXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset has PILImage images of range [0, 1]. \n",
        "# We transform them to Tensors of normalized range [-1, 1]\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                         shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "def imshow(img):\n",
        "  img = img / 2 + 0.5  # unnormalize\n",
        "  npimg = img.numpy()\n",
        "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))"
      ],
      "metadata": {
        "id": "aj863hmE-fDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**"
      ],
      "metadata": {
        "id": "1jVcBrtgUnZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    # origin shape: [32, 3, 32, 32] = 32, 3, 1024\n",
        "    # input_layer: 3 input channels, 64 output channels, 3 kernel size\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(images,beta)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1) % 200 == 0:\n",
        "      print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "U6CDnTz_UiNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving the model**"
      ],
      "metadata": {
        "id": "LZErdxYAUu59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = './cnn.pth'\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "UlgEE2ErUqgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing the model**"
      ],
      "metadata": {
        "id": "p9spTC7DU0VS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  n_class_correct = [0 for i in range(10)]\n",
        "  n_class_samples = [0 for i in range(10)]\n",
        "  for images, labels in test_loader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images,beta)\n",
        "    # max returns (value ,index)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    n_samples += labels.size(0)\n",
        "    n_correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    for i in range(outputs.shape[0]):\n",
        "      label = labels[i]\n",
        "      pred = predicted[i]\n",
        "      if (label == pred):\n",
        "          n_class_correct[label] += 1\n",
        "      n_class_samples[label] += 1\n",
        "\n",
        "  acc = 100.0 * n_correct / n_samples\n",
        "  print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "  for i in range(10):\n",
        "    acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "    print(f'Accuracy of {classes[i]}: {acc} %')\n"
      ],
      "metadata": {
        "id": "BSlr7HnXUzfL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
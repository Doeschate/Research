{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "u92IOHHTdBQ0",
        "aVvxBX0qPXgr",
        "KpRKSzm6PxuT",
        "ILVbj5xZNvXA",
        "TU4QlAabBFG3",
        "aThQppDQBRGg"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ld8fEDAWy3O2"
      },
      "outputs": [],
      "source": [
        "#@title Importing Packages\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "#save numpy array as npz file\n",
        "from numpy import asarray\n",
        "from numpy import savez_compressed\n",
        "# load numpy array from npz file\n",
        "from numpy import load\n",
        "\n",
        "from tqdm import tqdm as tqdm\n",
        "\n",
        "from scipy.linalg import eigh\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Device configuration\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "iA-2mvB_xYpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Z0EHnRI9kzlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Path**"
      ],
      "metadata": {
        "id": "ejmsLv92IdmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "absolute_path = os.path.abspath('')\n",
        "\n",
        "relative_path = \"/drive/MyDrive/Research/DLGN_Fashion_MNIST/Saved_models_25may/\" #for running in colab #Saved_models_25may/Saved_models_latest/Saved_models_2_class\n",
        "# relative_path = \"/Saved_models/\" #for local running\n",
        "\n",
        "file_path = absolute_path+relative_path\n"
      ],
      "metadata": {
        "id": "fDk5A22jGlAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Models\n",
        "\n",
        "'''\n",
        "Saved_models_latest\n",
        "'''\n",
        "\n",
        "# file_name1=\"DLGN_50_full_black_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_DLGN_50_full_black_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_50_white_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_DLGN_50_white_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_95_full_black_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_DLGN_95_full_black_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "\n",
        "# file_name1=\"DLGN_95_white_patch_no_extra_data_3L5N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_DLGN_95_white_patch_no_extra_data_3L5N_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_95_white_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_DLGN_95_white_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_no_patch_no_extra_data_3L100N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_DLGN_no_patch_no_extra_data_3L100N_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_no_patch_no_extra_data_3L5N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_DLGN_no_patch_no_extra_data_3L5N_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_no_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_DLGN_no_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_no_patch_no_extra_data_train_test_5_per_data_3L100N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_DLGN_no_patch_no_extra_data_train_test_5_per_data_3L100N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_no_patch_no_extra_data_train_test_5_per_data_3L5N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_DLGN_no_patch_no_extra_data_train_test_5_per_data_3L5N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_no_patch_no_extra_data_train_test_5_per_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_DLGN_no_patch_no_extra_data_train_test_5_per_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "\n",
        "########################################################################################################################\n",
        "\n",
        "# file_name1=\"ReLU_50_full_black_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_ReLU_50_full_black_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# file_name1=\"ReLU_50_white_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_ReLU_50_white_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# file_name1=\"ReLU_95_full_black_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_ReLU_95_full_black_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# file_name1=\"ReLU_95_white_patch_no_extra_data_3L100N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_ReLU_95_white_patch_no_extra_data_3L100N_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# file_name1=\"ReLU_95_white_patch_no_extra_data_3L5N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_ReLU_95_white_patch_no_extra_data_3L5N_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# file_name1=\"ReLU_95_white_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_ReLU_95_white_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# file_name1=\"ReLU_no_patch_no_extra_data_3L100N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_ReLU_no_patch_no_extra_data_3L100N_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# file_name1=\"ReLU_no_patch_no_extra_data_3L5N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_ReLU_no_patch_no_extra_data_3L5N_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# file_name1=\"ReLU_no_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_ReLU_no_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# file_name1=\"ReLU_no_patch_no_extra_data_train_test_5_per_data_3L100N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_ReLU_no_patch_no_extra_data_train_test_5_per_data_3L100N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# file_name1=\"ReLU_no_patch_no_extra_data_train_test_5_per_data_3L5N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_ReLU_no_patch_no_extra_data_train_test_5_per_data_3L5N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# file_name1=\"ReLU_no_patch_no_extra_data_train_test_5_per_data_lr_.001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_ReLU_no_patch_no_extra_data_train_test_5_per_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# file_name1=\"ReLU_no_patch_no_extra_data_train_test_5_per_data_lr_.001_epoch_2k_seed_365.npz\"\n",
        "# error_file=\"Error_ReLU_no_patch_no_extra_data_train_test_5_per_data_lr_.001_epoch_2k_seed_365.npz\"\n",
        "\n",
        "# file_name1=\"test_DLGN.npz\"\n",
        "# error_file=\"error_test_DLGN.npz\"\n",
        "\n",
        "##=======================================================================================================================\n",
        "'''\n",
        "New Training Algorithm\n",
        "----------------------\n",
        "1.Train both NPF and NPV for 10% epochs\n",
        "2.Reinitialize the NPF for half the neurons in each layer\n",
        "3.Freeze the NPF, train only NPV for 5% epochs\n",
        "4.Train both NPF and NPV for 85% epochs\n",
        "'''\n",
        "# file_name1=\"DLGN_95_white_patch_no_extra_data_lr_.0001_epoch_1k_seed_365_new_algo.npz\"\n",
        "# error_file=\"Error_DLGN_95_white_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365_new_algo.npz\"\n",
        "\n",
        "# file_name1=\"test.npz\"\n",
        "# error_file=\"error_test.npz\"\n",
        "\n",
        "##=======================================================================================================================\n",
        "##=======================================================================================================================\n",
        "\n",
        "'''\n",
        "Saved_models_25may\n",
        "'''\n",
        "\n",
        "'''\n",
        "100 Nodes\n",
        "'''\n",
        "##100 epochs\n",
        "\n",
        "# file_name1=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.001_epoch_100_seed_365_beta_20.npz\"\n",
        "# error_file=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_100_seed_365_beta_20.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_no_patch_no_extra_data_3L100N_lr_.001_epoch_100_seed_365_beta_20.npz\"\n",
        "# error_file=\"Error_DLGN_no_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_100_seed_365_beta_20.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_no_patch_no_extra_data_train_test_5_per_data_3L100N_lr_.001_epoch_100_seed_365_beta_20.npz\"\n",
        "# error_file=\"Error_DLGN_no_patch_no_extra_data_train_test_5_per_data_3L100N_lr_.001_epoch_100_seed_365_beta_20.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.001_epoch_100_seed_365_beta_20_new_algo_10_15.npz\"\n",
        "# error_file=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_100_seed_365_beta_20_new_algo_10_15.npz\"\n",
        "\n",
        "## 225 epochs\n",
        "\n",
        "# file_name1=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.001_epoch_225_seed_365_beta_20.npz\"\n",
        "# error_file=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_225_seed_365_beta_20.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_no_patch_no_extra_data_3L100N_lr_.001_epoch_225_seed_365_beta_20.npz\"\n",
        "# error_file=\"Error_DLGN_no_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_225_seed_365_beta_20.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_no_patch_no_extra_data_train_test_5_per_data_3L100N_lr_.001_epoch_225_seed_365_beta_20.npz\"\n",
        "# error_file=\"Error_DLGN_no_patch_no_extra_data_train_test_5_per_data_3L100N_lr_.001_epoch_225_seed_365_beta_20.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.001_epoch_225_seed_365_beta_20_new_algo_10_15.npz\"\n",
        "# error_file=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_225_seed_365_beta_20_new_algo_10_15.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.001_epoch_225_seed_365_beta_20_new_algo_2_10.npz\"\n",
        "# error_file=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_225_seed_365_beta_20_new_algo_2_10.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.001_epoch_225_seed_365_beta_20_new_algo_10_15_all_node_freeze.npz\"\n",
        "# error_file=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_225_seed_365_beta_20_new_algo_10_15_all_node_freeze.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.001_epoch_225_seed_365_beta_20_new_algo_2_10_all_node_freeze.npz\"\n",
        "# error_file=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_225_seed_365_beta_20_new_algo_2_10_all_node_freeze.npz\"\n",
        "\n",
        "## 225 epochs Beta 100\n",
        "\n",
        "# file_name1=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.001_epoch_225_seed_365_beta_100.npz\"\n",
        "# error_file=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_225_seed_365_beta_100.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_no_patch_no_extra_data_3L100N_lr_.001_epoch_225_seed_365_beta_100.npz\"\n",
        "# error_file=\"Error_DLGN_no_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_225_seed_365_beta_100.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_no_patch_no_extra_data_train_test_5_per_data_3L100N_lr_.001_epoch_225_seed_365_beta_100.npz\"\n",
        "# error_file=\"Error_DLGN_no_patch_no_extra_data_train_test_5_per_data_3L100N_lr_.001_epoch_225_seed_365_beta_100.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.001_epoch_225_seed_365_beta_100_new_algo_10_15.npz\"\n",
        "# error_file=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_225_seed_365_beta_100_new_algo_10_15.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.001_epoch_225_seed_365_beta_100_new_algo_2_10.npz\"\n",
        "# error_file=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_225_seed_365_beta_100_new_algo_2_10.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.001_epoch_225_seed_365_beta_100_new_algo_10_15_all_node_freeze.npz\"\n",
        "# error_file=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_225_seed_365_beta_100_new_algo_10_15.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.001_epoch_225_seed_365_beta_100_new_algo_2_10_all_node_freeze.npz\"\n",
        "# error_file=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_225_seed_365_beta_100_new_algo_2_10_all_node_freeze.npz\"\n",
        "\n",
        "'''\n",
        "10 Nodes\n",
        "'''\n",
        "# file_name1=\"DLGN_95_white_patch_no_extra_data_3L10N_lr_.001_epoch_100_seed_365_beta_20.npz\"\n",
        "# error_file=\"Error_DLGN_95_white_patch_no_extra_data_3L10N_train_test_lr_.001_epoch_100_seed_365_beta_20.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_no_patch_no_extra_data_3L10N_lr_.001_epoch_100_seed_365_beta_20.npz\"\n",
        "# error_file=\"Error_DLGN_no_patch_no_extra_data_3L10N_train_test_lr_.001_epoch_100_seed_365_beta_20.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_no_patch_no_extra_data_3L10N_train_test_5_per_data_lr_.001_epoch_100_seed_365_beta_20.npz\"\n",
        "# error_file=\"Error_DLGN_no_patch_no_extra_data_3L10N_train_test_5_per_data_lr_.001_epoch_100_seed_365_beta_20.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_95_white_patch_no_extra_data_3L10N_lr_.001_epoch_100_seed_365_beta_20_new_algo_10_15.npz\"\n",
        "# error_file=\"Error_DLGN_95_white_patch_no_extra_data_3L10N_train_test_lr_.001_epoch_100_seed_365_beta_20_new_algo_10_15.npz\"\n",
        "\n",
        "'''\n",
        "5 Nodes\n",
        "'''\n",
        "\n",
        "# file_name1=\"DLGN_95_white_patch_no_extra_data_3L5N_lr_.001_epoch_100_seed_365_beta_20.npz\"\n",
        "# error_file=\"Error_DLGN_95_white_patch_no_extra_data_3L5N_train_test_lr_.001_epoch_100_seed_365_beta_20.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_no_patch_no_extra_data_3L5N_lr_.001_epoch_100_seed_365_beta_20.npz\"\n",
        "# error_file=\"Error_DLGN_no_patch_no_extra_data_3L5N_train_test_lr_.001_epoch_100_seed_365_beta_20.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_no_patch_no_extra_data_train_test_5_per_data_3L5N_lr_.001_epoch_100_seed_365_beta_20.npz\"\n",
        "# error_file=\"Error_DLGN_no_patch_no_extra_data_train_test_5_per_data_3L5N_lr_.001_epoch_100_seed_365_beta_20.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_95_white_patch_no_extra_data_3L5N_lr_.001_epoch_100_seed_365_beta_20_new_algo_10_15.npz\"\n",
        "# error_file=\"Error_DLGN_95_white_patch_no_extra_data_3L5N_train_test_lr_.001_epoch_100_seed_365_beta_20_new_algo_10_15.npz\"\n",
        "\n",
        "\n",
        "'''\n",
        "Saved_models_2_class\n",
        "'''\n",
        "\n",
        "'''\n",
        "10 Nodes\n",
        "'''\n",
        "file_name1=\"DLGN_95_white_patch_no_extra_data_3L10N_lr_.001_epoch_225_seed_365_beta_20.npz\"\n",
        "error_file=\"Error_DLGN_95_white_patch_no_extra_data_3L10N_train_test_lr_.001_epoch_225_seed_365_beta_20.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_no_patch_no_extra_data_3L10N_lr_.001_epoch_225_seed_365_beta_20.npz\"\n",
        "# error_file=\"Error_DLGN_no_patch_no_extra_data_3L10N_train_test_lr_.001_epoch_225_seed_365_beta_20.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_no_patch_no_extra_data_3L10N_5_per_data_lr_.001_epoch_225_seed_365_beta_20.npz\"\n",
        "# error_file=\"Error_DLGN_no_patch_no_extra_data_3L10N_5_per_data_lr_.001_epoch_225_seed_365_beta_20.npz\"\n",
        "\n",
        "# file_name1=\"DLGN_95_white_patch_no_extra_data_3L10N_lr_.001_epoch_225_seed_365_beta_20_new_algo_10_15.npz\"\n",
        "# error_file=\"Error_DLGN_95_white_patch_no_extra_data_3L10N_lr_.001_epoch_225_seed_365_beta_20_new_algo_10_15.npz\"\n"
      ],
      "metadata": {
        "id": "ZVQj4gnkVL1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# file_name1=\"DLGN_50_full_black_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# file_name1=\"DLGN_50_white_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# file_name1=\"DLGN_95_full_black_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# file_name1=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# file_name1=\"DLGN_95_white_patch_no_extra_data_3L5N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# file_name1=\"DLGN_95_white_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# file_name1=\"DLGN_no_patch_no_extra_data_3L100N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# file_name1=\"DLGN_no_patch_no_extra_data_3L5N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# file_name1=\"DLGN_no_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# file_name1=\"DLGN_no_patch_no_extra_data_train_test_5_per_data_3L100N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# file_name1=\"DLGN_no_patch_no_extra_data_train_test_5_per_data_3L5N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# file_name1=\"DLGN_no_patch_no_extra_data_train_test_5_per_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# file_name1=\"ReLU_50_full_black_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# file_name1=\"ReLU_50_white_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# file_name1=\"ReLU_95_full_black_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# file_name1=\"ReLU_95_white_patch_no_extra_data_3L100N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# file_name1=\"ReLU_95_white_patch_no_extra_data_3L5N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# file_name1=\"ReLU_95_white_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# file_name1=\"ReLU_no_patch_no_extra_data_3L100N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# file_name1=\"ReLU_no_patch_no_extra_data_3L5N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# file_name1=\"ReLU_no_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# file_name1=\"ReLU_no_patch_no_extra_data_train_test_5_per_data_3L100N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# file_name1=\"ReLU_no_patch_no_extra_data_train_test_5_per_data_3L5N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# file_name1=\"ReLU_no_patch_no_extra_data_train_test_5_per_data_lr_.001_epoch_1k_seed_365.npz\"\n",
        "# file_name1=\"ReLU_no_patch_no_extra_data_train_test_5_per_data_lr_.001_epoch_2k_seed_365.npz\"\n",
        "# file_name1=\"test_DLGN.npz\""
      ],
      "metadata": {
        "id": "OmE6DALYg4xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# error_file=\"Error_DLGN_50_full_black_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_DLGN_50_white_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_DLGN_95_full_black_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_DLGN_95_white_patch_no_extra_data_3L5N_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_DLGN_95_white_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_DLGN_no_patch_no_extra_data_3L100N_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_DLGN_no_patch_no_extra_data_3L5N_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_DLGN_no_patch_no_extra_data_train_test_5_per_data_3L100N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_DLGN_no_patch_no_extra_data_train_test_5_per_data_3L5N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_DLGN_no_patch_no_extra_data_train_test_5_per_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_DLGN_no_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# error_file=\"Error_ReLU_50_full_black_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_ReLU_50_white_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_ReLU_95_full_black_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_ReLU_95_white_patch_no_extra_data_3L100N_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_ReLU_95_white_patch_no_extra_data_3L5N_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_ReLU_95_white_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_ReLU_no_patch_no_extra_data_3L100N_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_ReLU_no_patch_no_extra_data_3L5N_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_ReLU_no_patch_no_extra_data_train_test_5_per_data_3L100N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_ReLU_no_patch_no_extra_data_train_test_5_per_data_3L5N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_ReLU_no_patch_no_extra_data_train_test_5_per_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_file=\"Error_ReLU_no_patch_no_extra_data_train_test_5_per_data_lr_.001_epoch_2k_seed_365.npz\"\n",
        "# error_file=\"Error_ReLU_no_patch_no_extra_data_train_test_lr_.001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# error_file=\"error_test_DLGN.npz\"\n"
      ],
      "metadata": {
        "id": "JwnT_YOOg8pZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fashion MNIST"
      ],
      "metadata": {
        "id": "QI2VEqcb4E3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Parameters\n",
        "\n",
        "#DLGN(DLGN Model with only 3 linear layer containing 10,10,10 hidden nodes)\n",
        "#DeepnonLinearModel(Model with only 3 non linear layer containing 10,10,10 hidden nodes)\n",
        "\n",
        "#Replace any of the following in model_name to run that mode\n",
        "#DLGN/DeepnonLinearModel\n",
        "\n",
        "\n",
        "\n",
        "num_hidden_layers=3\n",
        "input_dim=784\n",
        "output_dim=10\n",
        "num_hidden_nodes=[10,10,10]\n",
        "modep='pwc'\n",
        "model_name = 'DLGN' #DLGN/DeepnonLinearModel\n",
        "batch_size = 64\n",
        "beta = 20\n",
        "epochs = 1000\n",
        "learning_rate = 0.0001\n",
        "optimizer_name ='SGD'\n",
        "num_of_classes = 10 #10 -> using all 10 classes of FMNIST\n",
        "n_corr_data = 95/100 #fraction of the data that is made corrupted\n",
        "corrupted_train = True #True - fraction of the data is corrupted, False- expt on real data w.o corruption\n",
        "corrupted_test = True\n",
        "use_x_percent_data = 100 #default:100. Percentage of the data used in training, if 100 use the full data as it is\n",
        "extra_data_train = False #True - Adding additional real data corresponding to the corrupted data, False- no addition\n",
        "extra_data_test = False\n",
        "simplified_patch_train = False #True - white patch and rest full black on train corrupted portion of the data\n",
        "simplified_patch_test = False #white patch and rest full black on test corrupted portion of the data\n",
        "model_training = False #True --> to train a new model else False\n",
        "model_inference = False #True --> to generate error files(error vs epoch plots) else false\n",
        "\n",
        "model_training_new_algo = False #False by default but if wants to train based on the new algo make it true\n",
        "seed = 365"
      ],
      "metadata": {
        "id": "0aw3Xyh7_njh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_npseed(seed):\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)\n",
        "\n",
        "def set_torchseed(seed):\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "we2FnxvM-ahu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_npseed(seed)"
      ],
      "metadata": {
        "id": "VQliknAV_XGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Dataset**"
      ],
      "metadata": {
        "id": "7nid_h-f7BDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#image transform and normalization\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,),(0.5,))])\n",
        "\n",
        "\n",
        "#defining train and test sets.\n",
        "trainset = torchvision.datasets.FashionMNIST('data',\n",
        "                                             download=True,\n",
        "                                             train=True,\n",
        "                                             transform=transform)\n",
        "testset = torchvision.datasets.FashionMNIST('data',\n",
        "                                            download=True,\n",
        "                                            train=False,\n",
        "                                            transform=transform)\n"
      ],
      "metadata": {
        "id": "C-o9oRKv6nFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important**"
      ],
      "metadata": {
        "id": "hOUq6PmbMxFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pytorch.org/docs/stable/_modules/torch/utils/data/dataloader.html#DataLoader\n",
        "# https://pytorch.org/docs/stable/data.html#module-torch.utils.data\n",
        "# https://pytorch.org/vision/main/generated/torchvision.transforms.ToTensor.html#totensor\n",
        "# https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "\n",
        "# trainset.data[1][:4,:4]=0 can be used to access and modify the data from actual dataset downloaded in __init__"
      ],
      "metadata": {
        "id": "dqTmQZnIKasj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainset[1][0][0][:4,:4] this is the data after transform that is used in training after taking index by index using __get_item()__ function and it is non-editable"
      ],
      "metadata": {
        "id": "7_meu0PrmNCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 100% data + n_corr_data% corrupted data\n",
        "#trainset\n",
        "if extra_data_train:\n",
        "  extra_train_data = torch.zeros(int(trainset.data.shape[0]*n_corr_data),trainset.data.shape[1],trainset.data.shape[2],dtype=torch.uint8)\n",
        "  extra_train_target = torch.zeros(int(trainset.targets.shape[0]*n_corr_data),dtype=torch.int64)\n",
        "\n",
        "  #testset\n",
        "if extra_data_test:\n",
        "  extra_test_data = torch.zeros(int(testset.data.shape[0]*n_corr_data),testset.data.shape[1],testset.data.shape[2],dtype=torch.uint8)\n",
        "  extra_test_target = torch.zeros(int(testset.targets.shape[0]*n_corr_data),dtype=torch.int64)"
      ],
      "metadata": {
        "id": "33zXbXt5xXsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Left 4x4 n_corr_data% data 5 classes, right 4x4 n_corr_data% data for 5 classes**\n",
        "if num_of_classes==10:\n",
        "  if corrupted_train:\n",
        "    #train_set\n",
        "    count_corrupt = 0\n",
        "    count = len(trainset)//10\n",
        "    count_class= [0,0,0,0,0,0,0,0,0,0]\n",
        "    for i in range(len(trainset)):\n",
        "      data_class = trainset.targets[i].item()\n",
        "      if((data_class<5)&(count_class[data_class]<count*n_corr_data)):\n",
        "        if extra_data_train:\n",
        "          extra_train_data[count_corrupt]=trainset.data[i].detach().clone()\n",
        "          extra_train_target[count_corrupt]=trainset.targets[i].detach().clone()\n",
        "\n",
        "          # print(extra_train_target[count_corrupt])\n",
        "          count_corrupt=count_corrupt+1\n",
        "        trainset.data[i][0+6*data_class:4+6*data_class,0:4]=255\n",
        "        if simplified_patch_train:\n",
        "          rest_black = torch.zeros(trainset.data[i].shape)\n",
        "          rest_black[0+6*data_class:4+6*data_class,0:4]=255\n",
        "          trainset.data[i] = rest_black\n",
        "        trainset.targets[i]=(trainset.targets[i]+10) #added to differentiate the corrupted data from the uncorrupted data, corrupted data will have target value as target value+10\n",
        "        count_class[data_class]+=1\n",
        "      if((data_class>=5)&(count_class[data_class]<count*n_corr_data)):\n",
        "        if extra_data_train:\n",
        "          extra_train_data[count_corrupt]=trainset.data[i].detach().clone()\n",
        "          extra_train_target[count_corrupt]=trainset.targets[i].detach().clone()\n",
        "          count_corrupt=count_corrupt+1\n",
        "        trainset.data[i][0+6*(data_class-5):4+6*(data_class-5),-4:]=255\n",
        "        if simplified_patch_train:\n",
        "          rest_black = torch.zeros(trainset.data[i].shape)\n",
        "          rest_black[0+6*(data_class-5):4+6*(data_class-5),-4:]=255\n",
        "          trainset.data[i] = rest_black\n",
        "        trainset.targets[i]=(trainset.targets[i]+10)\n",
        "        count_class[data_class]+=1\n",
        "\n",
        "    #test_set\n",
        "  if corrupted_test:\n",
        "    count_corrupt_test = 0\n",
        "    count_test = len(testset)//10\n",
        "    count_class_test= [0,0,0,0,0,0,0,0,0,0]\n",
        "    for i in range(len(testset)):\n",
        "      data_class_test = testset.targets[i].item()\n",
        "      if((data_class_test<5)&(count_class_test[data_class_test]<count_test*n_corr_data)):\n",
        "        if extra_data_test:\n",
        "          extra_test_data[count_corrupt_test]=testset.data[i].detach().clone()\n",
        "          extra_test_target[count_corrupt_test]=testset.targets[i].detach().clone()\n",
        "          count_corrupt_test=count_corrupt_test+1\n",
        "        testset.data[i][0+6*data_class_test:4+6*data_class_test,0:4]=255\n",
        "        if simplified_patch_test:\n",
        "          rest_black = torch.zeros(testset.data[i].shape)\n",
        "          rest_black[0+6*data_class_test:4+6*data_class_test,0:4]=255\n",
        "          testset.data[i] = rest_black\n",
        "        testset.targets[i]=(testset.targets[i]+10)\n",
        "        count_class_test[data_class_test]+=1\n",
        "      if((data_class_test>=5)&(count_class_test[data_class_test]<count_test*n_corr_data)):\n",
        "        if extra_data_test:\n",
        "          extra_test_data[count_corrupt_test]=testset.data[i].detach().clone()\n",
        "          extra_test_target[count_corrupt_test]=testset.targets[i].detach().clone()\n",
        "          count_corrupt_test=count_corrupt_test+1\n",
        "        testset.data[i][0+6*(data_class_test-5):4+6*(data_class_test-5),-4:]=255\n",
        "        if simplified_patch_test:\n",
        "          rest_black = torch.zeros(testset.data[i].shape)\n",
        "          rest_black[0+6*(data_class_test-5):4+6*(data_class_test-5),-4:]=255\n",
        "          testset.data[i] = rest_black\n",
        "        testset.targets[i]=(testset.targets[i]+10)\n",
        "        count_class_test[data_class_test]+=1"
      ],
      "metadata": {
        "id": "qLjHcINrEbDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Custom Dataset\n",
        "class CustomDataset:\n",
        "  def __init__(self,data,targets):\n",
        "    self.data = data\n",
        "    self.targets = targets\n",
        "  def __len__(self):\n",
        "    return self.data.shape[0]\n",
        "  def __getitem__(self,idx):\n",
        "    current_sample = self.data[idx,:,:]\n",
        "    current_target = self.targets[idx]\n",
        "    return current_sample,current_target"
      ],
      "metadata": {
        "id": "5d0m4jSovZXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating x% training dataset\n",
        "if use_x_percent_data!=100:\n",
        "  data_size = int(trainset.targets.shape[0]*(use_x_percent_data/100))\n",
        "  train_data_x_per = torch.zeros(data_size,trainset.data.shape[1],trainset.data.shape[2],dtype=torch.uint8)\n",
        "  train_target_x_per = torch.zeros(data_size,dtype=torch.int64)\n",
        "  train_data_x_per[0:data_size]=trainset.data[0:data_size].detach().clone()\n",
        "  train_target_x_per[0:data_size]=trainset.targets[0:data_size].detach().clone()\n",
        "  train_dataset = CustomDataset(data=train_data_x_per, targets= train_target_x_per)\n",
        "  trainset.data=train_dataset.data\n",
        "  trainset.targets = train_dataset.targets\n"
      ],
      "metadata": {
        "id": "eXVKhZoD8Tm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if extra_data_train:\n",
        "  train_dataset_extra = CustomDataset(data=extra_train_data, targets= extra_train_target)\n",
        "  trainset.data = torch.vstack([trainset.data,train_dataset_extra.data])\n",
        "  trainset.targets = torch.cat([trainset.targets,train_dataset_extra.targets])\n",
        "\n",
        "if extra_data_test:\n",
        "  test_dataset_extra = CustomDataset(data=extra_test_data, targets= extra_test_target)\n",
        "  testset.data = torch.vstack([testset.data,test_dataset_extra.data])\n",
        "  testset.targets = torch.cat([testset.targets,test_dataset_extra.targets])"
      ],
      "metadata": {
        "id": "4A7jHoz0Jx8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating dataloaders for both training and testing\n",
        "trainloader = torch.utils.data.DataLoader(trainset,batch_size = batch_size,\n",
        "                                        shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset,batch_size = batch_size,\n",
        "                                      shuffle=False)\n"
      ],
      "metadata": {
        "id": "AKmmri2_bUpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #constant for different classes in the dataset\n",
        "# classes = ('T-shirt/top','Trouser','Pullover','Dress','Coat'\n",
        "#       ,'Sandal','Shirt','Sneaker','Bag','Ankle Boot')\n",
        "\n",
        "#function to show an image\n",
        "def matplotlib_imshow(img, one_channel=False):\n",
        "  if one_channel:\n",
        "    img=img.mean(dim=0)\n",
        "  # img = img/2 + 0.5 #unnormalize\n",
        "  npimg = img.numpy()\n",
        "  if one_channel:\n",
        "    plt.imshow(npimg, cmap=\"gray\")\n",
        "    plt.colorbar()\n",
        "  else:\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
        "    plt.colorbar()"
      ],
      "metadata": {
        "id": "VEQDjTpmbiwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualizing Training Examples**"
      ],
      "metadata": {
        "id": "BeDwetM5jWQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "images,labels = next(dataiter)\n",
        "matplotlib_imshow(torchvision.utils.make_grid(images),True)"
      ],
      "metadata": {
        "id": "SgvkiFI760n-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **DLGN_FC**\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "class DLGN_FC(nn.Module):\n",
        "  def __init__(self, to_copy=None, num_hidden_layers=0, input_dim=784, output_dim=10, num_hidden_nodes=[], beta=20, mode='pwc'):\n",
        "    super(DLGN_FC, self).__init__()\n",
        "    if to_copy==None:\n",
        "      self.gating_layers=[]\n",
        "      self.value_layers=[]\n",
        "      self.num_hidden_layers = num_hidden_layers\n",
        "      self.beta=beta  # Soft gating parameter\n",
        "      self.mode = mode\n",
        "      self.num_nodes=[input_dim]+num_hidden_nodes+[output_dim]\n",
        "      for i in range(num_hidden_layers+1):\n",
        "        self.gating_layers.append(nn.Linear(self.num_nodes[i], self.num_nodes[i+1]))\n",
        "        self.value_layers.append(nn.Linear(self.num_nodes[i], self.num_nodes[i+1], bias=False))\n",
        "    else:\n",
        "      self.gating_layers=[]\n",
        "      self.value_layers=[]\n",
        "      self.num_hidden_layers = to_copy.num_hidden_layers\n",
        "      self.beta=to_copy.beta  # Soft gating parameter\n",
        "      self.mode = to_copy.mode\n",
        "      self.num_nodes=list(to_copy.num_nodes)\n",
        "      for i in range(self.num_hidden_layers+1):\n",
        "        self.gating_layers.append(nn.Linear(self.num_nodes[i], self.num_nodes[i+1]))\n",
        "        self.value_layers.append(nn.Linear(self.num_nodes[i], self.num_nodes[i+1], bias=False))\n",
        "        self.gating_layers[i].weight.data =  torch.Tensor(np.array(to_copy.gating_layers[i].cpu().weight.detach().numpy()))\n",
        "        self.gating_layers[i].bias.data = torch.Tensor(np.array(to_copy.gating_layers[i].cpu().bias.detach().numpy()))\n",
        "        self.value_layers[i].weight.data = torch.Tensor(np.array(to_copy.value_layers[i].cpu().weight.detach().numpy()))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def return_gating_functions(self):\n",
        "    effective_weights = []\n",
        "    effective_biases =[]\n",
        "    for i in range(self.num_hidden_layers):\n",
        "      curr_weight = self.gating_layers[i].weight\n",
        "      curr_bias = self.gating_layers[i].bias\n",
        "      if i==0:\n",
        "        effective_weights.append(curr_weight)\n",
        "        effective_biases.append(curr_bias)\n",
        "      else:\n",
        "        effective_biases.append(torch.matmul(curr_weight,effective_biases[-1])+curr_bias)\n",
        "        effective_weights.append(torch.matmul(curr_weight,effective_weights[-1]))\n",
        "    return effective_weights, effective_biases\n",
        "    # effective_weights (and effective biases) is a list of size num_hidden_layers\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x=x.view(x.shape[0],-1)\n",
        "    gate_scores=[x.to(device)]\n",
        "    if self.mode=='pwc':\n",
        "      values=[torch.ones(x.shape).to(device)]\n",
        "    else:\n",
        "      values=[x.to(device)]\n",
        "    for i in range(self.num_hidden_layers):\n",
        "      gate_scores.append(self.gating_layers[i].to(device)(gate_scores[-1].to(device)))\n",
        "      curr_gate_on_off = torch.sigmoid(beta*gate_scores[-1].to(device)).to(device)\n",
        "      values.append(self.value_layers[i].to(device)(values[-1].to(device))*curr_gate_on_off.to(device))\n",
        "    values.append(self.value_layers[self.num_hidden_layers].to(device)(values[-1].to(device)).to(device))\n",
        "    # Values is a list of size 1+num_hidden_layers+1\n",
        "    #gate_scores is a list of size 1+num_hidden_layers\n",
        "    return values,gate_scores"
      ],
      "metadata": {
        "id": "KmqBpq3mmZFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DNN Architecture**"
      ],
      "metadata": {
        "id": "g_Z7odtLtIYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **DNL_FC**\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "class DNL_FC(nn.Module):\n",
        "  def __init__(self, to_copy=None, num_hidden_layers=0, input_dim=784, output_dim=10, num_hidden_nodes=[]):\n",
        "    super(DNL_FC, self).__init__()\n",
        "    if to_copy==None:\n",
        "      self.gating_layers=[]\n",
        "      self.num_hidden_layers = num_hidden_layers\n",
        "      self.num_nodes=[input_dim]+num_hidden_nodes+[output_dim]\n",
        "      for i in range(num_hidden_layers+1):\n",
        "        self.gating_layers.append(nn.Linear(self.num_nodes[i], self.num_nodes[i+1],device=device).to(device))\n",
        "    else:\n",
        "      self.gating_layers=[]\n",
        "      self.num_hidden_layers = to_copy.num_hidden_layers\n",
        "      self.num_nodes=list(to_copy.num_nodes)\n",
        "      for i in range(self.num_hidden_layers+1):\n",
        "        self.gating_layers.append(nn.Linear(self.num_nodes[i], self.num_nodes[i+1],device=device).to(device))\n",
        "        self.gating_layers[i].weight.data =  torch.Tensor(np.array(to_copy.gating_layers[i].cpu().weight.detach().numpy()))\n",
        "        self.gating_layers[i].bias.data = torch.Tensor(np.array(to_copy.gating_layers[i].cpu().bias.detach().numpy()))\n",
        "\n",
        "\n",
        "\n",
        "  def return_gating_functions(self):\n",
        "    effective_weights = []\n",
        "    effective_biases =[]\n",
        "    for i in range(self.num_hidden_layers):\n",
        "      curr_weight = self.gating_layers[i].weight\n",
        "      curr_bias = self.gating_layers[i].bias\n",
        "      if i==0:\n",
        "        effective_weights.append(curr_weight)\n",
        "        effective_biases.append(curr_bias)\n",
        "      else:\n",
        "        effective_biases.append(torch.matmul(curr_weight,effective_biases[-1])+curr_bias)\n",
        "        effective_weights.append(torch.matmul(curr_weight,effective_weights[-1]))\n",
        "    return effective_weights, effective_biases\n",
        "    # effective_weights (and effective biases) is a list of size num_hidden_layers\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x=x.view(x.shape[0],-1)\n",
        "    gate_scores=[x]\n",
        "\n",
        "    for i in range(self.num_hidden_layers):\n",
        "      gate_scores.append(F.relu(self.gating_layers[i].to(device)(gate_scores[-1].to(device)).to(device)))\n",
        "    gate_scores.append(F.log_softmax(self.gating_layers[self.num_hidden_layers].to(device)(gate_scores[-1].to(device)).to(device),dim=1))\n",
        "    return gate_scores"
      ],
      "metadata": {
        "id": "PHyLivy_Ujg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Check perfect sq**\n",
        "def perfectSq(N) :\n",
        "\tsq_root = round(N**(1/2));\n",
        "\tif sq_root * sq_root == N :\n",
        "\t\treturn True;\n",
        "\telse :\n",
        "\t\treturn False;"
      ],
      "metadata": {
        "id": "fJmIQ72DIMqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "KpJdTAumF837"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Train model**\n",
        "def train_model(seed,num_hidden_layers,input_dim,output_dim,num_hidden_nodes,beta,batch_size,mode,num_epoch):\n",
        "  set_torchseed(seed)\n",
        "  Model_obj = None\n",
        "\n",
        "  if model_name == 'DLGN':\n",
        "    Model_obj = DLGN_FC(num_hidden_layers=num_hidden_layers, input_dim=input_dim, output_dim=output_dim,\n",
        "                        num_hidden_nodes=num_hidden_nodes, beta=beta, mode=mode)\n",
        "\n",
        "\n",
        "  if model_name == 'DeepnonLinearModel':\n",
        "    Model_obj = DNL_FC(num_hidden_layers=num_hidden_layers, input_dim=input_dim, output_dim=output_dim,\n",
        "                        num_hidden_nodes=num_hidden_nodes)\n",
        "\n",
        "\n",
        "  Model_obj=Model_obj.to(device)\n",
        "\n",
        "\n",
        "  Model_params = []\n",
        "  Model_params += [item.weight for item in Model_obj.gating_layers]\n",
        "  Model_params += [item.bias for item in Model_obj.gating_layers]\n",
        "  if model_name == 'DLGN':\n",
        "    Model_params += [item.weight for item in Model_obj.value_layers]\n",
        "\n",
        "\n",
        "\n",
        "  if optimizer_name == 'SGD':\n",
        "    optimizer = optim.SGD(Model_params, lr=learning_rate)\n",
        "  if optimizer_name == 'Adam':\n",
        "    optimizer = optim.Adam(Model_params, lr=learning_rate)\n",
        "\n",
        "  criterion = nn.NLLLoss()\n",
        "\n",
        "  losses=[]\n",
        "  Model_obj_store = []\n",
        "\n",
        "  for epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    if perfectSq(epoch):\n",
        "      if model_name == 'DLGN':\n",
        "        Model_obj_store.append(DLGN_FC(to_copy=Model_obj))\n",
        "      if model_name == 'DeepnonLinearModel':\n",
        "        Model_obj_store.append(DNL_FC(to_copy=Model_obj))\n",
        "\n",
        "    for images,labels in trainloader:\n",
        "      optimizer.zero_grad()\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      if model_name == 'DLGN':\n",
        "        values,gate_scores = Model_obj(images)\n",
        "        loss = criterion(F.log_softmax(values[-1],dim=1),labels%10)\n",
        "      if model_name == 'DeepnonLinearModel':\n",
        "        gate_scores = Model_obj(images)\n",
        "        loss = criterion(gate_scores[-1],labels%10)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      running_loss += loss.item()\n",
        "    losses.append(running_loss/len(trainloader))\n",
        "\n",
        "  return losses, Model_obj_store"
      ],
      "metadata": {
        "id": "lp4tox4nnNEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **New Algo Train model**\n",
        "\n",
        "'''\n",
        "New Training Algorithm\n",
        "----------------------\n",
        "1.Train both NPF and NPV for 10% epochs\n",
        "2.Reinitialize the NPF for half the neurons in each layer\n",
        "3.Freeze the NPF, train only NPV for 5% epochs\n",
        "4.Train both NPF and NPV for 85% epochs\n",
        "'''\n",
        "\n",
        "def train_model_new_algo(seed,num_hidden_layers,input_dim,output_dim,num_hidden_nodes,beta,batch_size,mode,num_epoch,epoch_1,epoch_2):\n",
        "  set_torchseed(seed)\n",
        "  Model_obj = None\n",
        "  Model_obj_initial = None\n",
        "\n",
        "  if model_name == 'DLGN':\n",
        "    Model_obj = DLGN_FC(num_hidden_layers=num_hidden_layers, input_dim=input_dim, output_dim=output_dim,\n",
        "                        num_hidden_nodes=num_hidden_nodes, beta=beta, mode=mode)\n",
        "    Model_obj_initial = DLGN_FC(to_copy=Model_obj)\n",
        "\n",
        "\n",
        "  if model_name == 'DeepnonLinearModel':\n",
        "    Model_obj = DNL_FC(num_hidden_layers=num_hidden_layers, input_dim=input_dim, output_dim=output_dim,\n",
        "                        num_hidden_nodes=num_hidden_nodes)\n",
        "\n",
        "\n",
        "  Model_obj=Model_obj.to(device)\n",
        "  Model_obj_initial=Model_obj_initial.to(device)\n",
        "\n",
        "  Model_params = []\n",
        "  Model_params += [item.weight for item in Model_obj.gating_layers]\n",
        "  Model_params += [item.bias for item in Model_obj.gating_layers]\n",
        "  if model_name == 'DLGN':\n",
        "    Model_params += [item.weight for item in Model_obj.value_layers]\n",
        "\n",
        "  # print(Model_params)\n",
        "\n",
        "  if optimizer_name == 'SGD':\n",
        "    optimizer = optim.SGD(Model_params, lr=learning_rate)\n",
        "  if optimizer_name == 'Adam':\n",
        "    optimizer = optim.Adam(Model_params, lr=learning_rate)\n",
        "\n",
        "  criterion = nn.NLLLoss()\n",
        "\n",
        "  losses=[]\n",
        "  Model_obj_store = []\n",
        "\n",
        "  for epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    if perfectSq(epoch):\n",
        "      if model_name == 'DLGN':\n",
        "        Model_obj_store.append(DLGN_FC(to_copy=Model_obj))\n",
        "      if model_name == 'DeepnonLinearModel':\n",
        "        Model_obj_store.append(DNL_FC(to_copy=Model_obj))\n",
        "\n",
        "    for images,labels in trainloader:\n",
        "      optimizer.zero_grad()\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      if model_name == 'DLGN':\n",
        "        values,gate_scores = Model_obj(images)\n",
        "        loss = criterion(F.log_softmax(values[-1],dim=1),labels%10)\n",
        "      if model_name == 'DeepnonLinearModel':\n",
        "        gate_scores = Model_obj(images)\n",
        "        loss = criterion(gate_scores[-1],labels%10)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if epoch>=epoch_1 and epoch<epoch_2:\n",
        "        #setting half of the node weights to initial node weights\n",
        "        for layers in range(num_hidden_layers):\n",
        "          Model_params[layers].data[num_hidden_nodes[0]//2:]= Model_obj_initial.gating_layers[layers].weight.data[num_hidden_nodes[0]//2:]\n",
        "          Model_params[len(Model_obj.gating_layers)+layers].data[num_hidden_nodes[0]//2:]= Model_obj_initial.gating_layers[layers].bias.data[num_hidden_nodes[0]//2:]\n",
        "        if epoch==epoch_1: #set requires_grad=False for NPF params\n",
        "          for index,param in enumerate(Model_params):\n",
        "            if(index<2*len(Model_obj.gating_layers)):\n",
        "              param.requires_grad=False\n",
        "\n",
        "      if epoch==epoch_2: #set requires_grad=False for NPF params\n",
        "        for index,param in enumerate(Model_params):\n",
        "          if(index<2*len(Model_obj.gating_layers)):\n",
        "            param.requires_grad=True\n",
        "\n",
        "      running_loss += loss.item()\n",
        "    losses.append(running_loss/len(trainloader))\n",
        "    # print(epoch,Model_params)\n",
        "  return losses, Model_obj_store"
      ],
      "metadata": {
        "id": "9ewQjuOG8jr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if model_training:\n",
        "  if model_training_new_algo:\n",
        "    epoch_1=100\n",
        "    epoch_2=150\n",
        "    losses, model_store = train_model_new_algo(seed,num_hidden_layers,input_dim,output_dim,num_hidden_nodes,beta,batch_size,\n",
        "                  modep,epochs,epoch_1,epoch_2)\n",
        "  else:\n",
        "    losses, model_store = train_model(seed,num_hidden_layers,input_dim,output_dim,num_hidden_nodes,beta,batch_size,\n",
        "                  modep,epochs)\n",
        "\n",
        "    # save to npy file\n",
        "  file_name=file_path+file_name1\n",
        "  savez_compressed(file_name, losses, model_store)"
      ],
      "metadata": {
        "id": "IE6-05HMbGsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inferencing**"
      ],
      "metadata": {
        "id": "o6p0vOfGGGI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inference Loop\n",
        "def eval_fun(corrupted,data_loader,model):\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  if corrupted:\n",
        "    total_corrupted = 0\n",
        "    correct_corrupted = 0\n",
        "    total_real = 0\n",
        "    correct_real = 0\n",
        "\n",
        "  #evaluation\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for images,labels in data_loader:\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      if model_name == 'DLGN':\n",
        "        values,gate_scores = model(images)\n",
        "        max_index = torch.argmax(F.log_softmax(values[-1],dim=1),dim=1)\n",
        "      if model_name == 'DeepnonLinearModel':\n",
        "        gate_scores = model(images)\n",
        "        max_index = torch.argmax(gate_scores[-1],dim=1)\n",
        "      total+=labels.numel()\n",
        "      correct+=sum(max_index==(labels%10)).item()\n",
        "\n",
        "    #For separate corrupted and real train images\n",
        "      if corrupted:\n",
        "        idx_corr=labels>9\n",
        "        total_corrupted += idx_corr.sum().item()\n",
        "        correct_corrupted+=(sum((labels[idx_corr]%10)==max_index[idx_corr]))\n",
        "        idx_real=labels<=9\n",
        "        total_real+=idx_real.sum().item()\n",
        "        correct_real+=sum((labels[idx_real]%10)==max_index[idx_real])\n",
        "        # for lb in range(len(labels)):\n",
        "        #   if(labels[lb]>9):\n",
        "        #     total_corrupted+=1\n",
        "        #     correct_corrupted+=((labels[lb]%10)==max_index[lb]).item()\n",
        "        #   else:\n",
        "        #     total_real+=1\n",
        "        #     correct_real+=((labels[lb]%10)==max_index[lb]).item()\n",
        "    loss_z_o = (total-correct)/(total)\n",
        "    if corrupted:\n",
        "      loss_z_o_corrupted = (total_corrupted-correct_corrupted)/(total_corrupted)\n",
        "      loss_z_o_real = (total_real-correct_real)/(total_real)\n",
        "      # print(total,total_corrupted,total_real)\n",
        "      # print(correct,correct_corrupted,correct_real)\n",
        "    acc=(correct/total*100)\n",
        "  if corrupted:\n",
        "    return acc,loss_z_o,loss_z_o_corrupted,loss_z_o_real\n",
        "  else:\n",
        "    return acc,loss_z_o\n"
      ],
      "metadata": {
        "id": "g3sbRcj-_Saf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if model_inference:\n",
        "  max_epoch=0\n",
        "  max_acc=0\n",
        "  epoch_count = []\n",
        "  train_error = []\n",
        "  test_error = []\n",
        "\n",
        "  if corrupted_train:\n",
        "    train_corrupted_error = []\n",
        "    train_real_error = []\n",
        "  if corrupted_test:\n",
        "    test_corrupted_error = []\n",
        "    test_real_error = []\n",
        "\n",
        "\n",
        "  file_name_load  = file_path + file_name1\n",
        "  # load numpy array from npz file\n",
        "  # load dict of arrays\n",
        "  dict_data = load(file_name_load,allow_pickle=True)\n",
        "  losses=dict_data['arr_0']\n",
        "  model_store=dict_data['arr_1']\n",
        "\n",
        "  for index in range(len(model_store)):\n",
        "    model=model_store[index]\n",
        "    #Calculating the error for training data\n",
        "    if corrupted_train:\n",
        "      acc,loss_z_o_train,loss_z_o_corrupted_train,loss_z_o_real_train = eval_fun(corrupted_train,trainloader,model)\n",
        "    else:\n",
        "      acc,loss_z_o_train = eval_fun(corrupted_train,trainloader,model)\n",
        "    train_error.append(loss_z_o_train)\n",
        "    if corrupted_train:\n",
        "      train_corrupted_error.append(loss_z_o_corrupted_train)\n",
        "      train_real_error.append(loss_z_o_real_train)\n",
        "\n",
        "    # print(f\"Epoch[{e}/{epochs}]: Training loss:{running_loss/1000}\",end=\" \")\n",
        "    print(f\"Epoch[{index*index}/{epochs}]: Training zero_one loss:{loss_z_o_train}\")\n",
        "    # print(f\"Epoch[{e}/{epochs}]: Training zero_one corrupted image loss:{loss_z_o_corrupted_train}\",end=\" \")\n",
        "    # print(f\"Epoch[{e}/{epochs}]: Training zero_one real image loss:{loss_z_o_real_train}\",end=\" \")\n",
        "\n",
        "\n",
        "    #Calculating the error for test data\n",
        "    if corrupted_test:\n",
        "      acc,loss_z_o_test,loss_z_o_corrupted_test,loss_z_o_real_test = eval_fun(corrupted_test,testloader,model)\n",
        "    else:\n",
        "      acc,loss_z_o_test = eval_fun(corrupted_test,testloader,model)\n",
        "    test_error.append(loss_z_o_test)\n",
        "    if corrupted_test:\n",
        "      test_corrupted_error.append(loss_z_o_corrupted_test)\n",
        "      test_real_error.append(loss_z_o_real_test)\n",
        "\n",
        "    # print(f\"Test Accuracy {acc:.2f}\",end=\" \")\n",
        "    print(f\"Test Error {loss_z_o_test}\")\n",
        "    # print(f\"Test Error corrupted images {loss_z_o_corrupted_test}\",end=\" \")\n",
        "    # print(f\"Test Error real images {loss_z_o_real_test}\")\n",
        "\n",
        "    epoch_count.append(index)\n",
        "\n",
        "    if(acc>max_acc):\n",
        "      max_acc = acc\n",
        "      max_epoch = index\n",
        "\n",
        "  file_name_error=file_path+error_file\n",
        "  if(corrupted_train and corrupted_test):\n",
        "    savez_compressed(file_name_error, max_epoch,max_acc,epoch_count,train_error,test_error,train_corrupted_error,train_real_error,test_corrupted_error,test_real_error)\n",
        "  elif(corrupted_train):\n",
        "    savez_compressed(file_name_error, max_epoch,max_acc,epoch_count,train_error,test_error,train_corrupted_error,train_real_error)\n",
        "  elif(corrupted_test):\n",
        "    savez_compressed(file_name_error, max_epoch,max_acc,epoch_count,train_error,test_error,test_corrupted_error,test_real_error)\n",
        "  else:\n",
        "    savez_compressed(file_name_error, max_epoch,max_acc,epoch_count,train_error,test_error)\n",
        "\n"
      ],
      "metadata": {
        "id": "9sa-TjaWFPkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DLGN\n",
        "\n",
        "# DLGN_50_full_black_patch_3L10N=\"DLGN_50_full_black_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# DLGN_50_white_patch_3L10N=\"DLGN_50_white_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# DLGN_95_full_black_patch_3L10N=\"DLGN_95_full_black_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "## 3L10N\n",
        "DLGN_95_white_patch_3L10N=\"DLGN_95_white_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "DLGN_no_patch_3L10N=\"DLGN_no_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "DLGN_no_patch_5_percent_3L10N=\"DLGN_no_patch_no_extra_data_train_test_5_per_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "## 3L100N\n",
        "DLGN_95_white_patch_3L100N=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "DLGN_no_patch_3L100N=\"DLGN_no_patch_no_extra_data_3L100N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "DLGN_no_patch_5_percent_3L100N=\"DLGN_no_patch_no_extra_data_train_test_5_per_data_3L100N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "## 3L5N\n",
        "DLGN_95_white_patch_3L5N=\"DLGN_95_white_patch_no_extra_data_3L5N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "DLGN_no_patch_3L5N=\"DLGN_no_patch_no_extra_data_3L5N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "DLGN_no_patch_5_percent_3L5N=\"DLGN_no_patch_no_extra_data_train_test_5_per_data_3L5N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "'''\n",
        "New Algo\n",
        "'''\n",
        "## 3L10N\n",
        "DLGN_95_white_patch_3L10N_new_algo=\"DLGN_95_white_patch_no_extra_data_lr_.0001_epoch_1k_seed_365_new_algo.npz\"\n",
        "DLGN_no_patch_3L10N=\"DLGN_no_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "DLGN_no_patch_5_percent_3L10N=\"DLGN_no_patch_no_extra_data_train_test_5_per_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "'''\n",
        "Saved_models_25may\n",
        "'''\n",
        "\n",
        "'''\n",
        "100 Nodes\n",
        "'''\n",
        "\n",
        "'''\n",
        "100\n",
        "'''\n",
        "\n",
        "DLGN_95_white_patch_lr_001_epoch_100_3L100N=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.001_epoch_100_seed_365_beta_20.npz\"\n",
        "DLGN_no_patch_lr_001_epoch_100_3L100N=\"DLGN_no_patch_no_extra_data_3L100N_lr_.001_epoch_100_seed_365_beta_20.npz\"\n",
        "DLGN_no_patch_5_percent_lr_001_epoch_100_3L100N=\"DLGN_no_patch_no_extra_data_train_test_5_per_data_3L100N_lr_.001_epoch_100_seed_365_beta_20.npz\"\n",
        "DLGN_95_white_patch_lr_001_epoch_100_3L100N_new_algo=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.001_epoch_100_seed_365_beta_20_new_algo_10_15.npz\"\n",
        "\n",
        "'''\n",
        "225\n",
        "'''\n",
        "DLGN_95_white_patch_lr_001_epoch_225_3L100N=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.001_epoch_225_seed_365_beta_20.npz\"\n",
        "DLGN_no_patch_lr_001_epoch_225_3L100N=\"DLGN_no_patch_no_extra_data_3L100N_lr_.001_epoch_225_seed_365_beta_20.npz\"\n",
        "DLGN_no_patch_5_percent_lr_001_epoch_225_3L100N=\"DLGN_no_patch_no_extra_data_train_test_5_per_data_3L100N_lr_.001_epoch_225_seed_365_beta_20.npz\"\n",
        "DLGN_95_white_patch_lr_001_epoch_225_3L100N_new_algo_2_10=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.001_epoch_225_seed_365_beta_20_new_algo_2_10.npz\"\n",
        "DLGN_95_white_patch_lr_001_epoch_225_3L100N_new_algo_10_15=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.001_epoch_225_seed_365_beta_20_new_algo_10_15.npz\"\n",
        "DLGN_95_white_patch_lr_001_epoch_225_3L100N_new_algo_2_10_all_node_freeze=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.001_epoch_225_seed_365_beta_20_new_algo_2_10_all_node_freeze.npz\"\n",
        "DLGN_95_white_patch_lr_001_epoch_225_3L100N_new_algo_10_15_all_node_freeze=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.001_epoch_225_seed_365_beta_20_new_algo_10_15_all_node_freeze.npz\"\n",
        "\n",
        "'''\n",
        "225 Beta 100\n",
        "'''\n",
        "DLGN_95_white_patch_lr_001_epoch_225_3L100N_beta_100=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.001_epoch_225_seed_365_beta_100.npz\"\n",
        "DLGN_no_patch_lr_001_epoch_225_3L100N_beta_100=\"DLGN_no_patch_no_extra_data_3L100N_lr_.001_epoch_225_seed_365_beta_100.npz\"\n",
        "DLGN_no_patch_5_percent_lr_001_epoch_225_3L100N_beta_100=\"DLGN_no_patch_no_extra_data_train_test_5_per_data_3L100N_lr_.001_epoch_225_seed_365_beta_100.npz\"\n",
        "DLGN_95_white_patch_lr_001_epoch_225_3L100N_new_algo_2_10_beta_100=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.001_epoch_225_seed_365_beta_100_new_algo_2_10.npz\"\n",
        "DLGN_95_white_patch_lr_001_epoch_225_3L100N_new_algo_10_15_beta_100=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.001_epoch_225_seed_365_beta_100_new_algo_10_15.npz\"\n",
        "DLGN_95_white_patch_lr_001_epoch_225_3L100N_new_algo_2_10_beta_100_all_node_freeze=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.001_epoch_225_seed_365_beta_100_new_algo_2_10_all_node_freeze.npz\"\n",
        "DLGN_95_white_patch_lr_001_epoch_225_3L100N_new_algo_10_15_beta_100_all_node_freeze=\"DLGN_95_white_patch_no_extra_data_3L100N_lr_.001_epoch_225_seed_365_beta_100_new_algo_10_15_all_node_freeze.npz\"\n",
        "\n",
        "\n",
        "\n",
        "# ReLU\n",
        "\n",
        "# ReLU_50_full_black_patch_3L10N=\"ReLU_50_full_black_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# ReLU_50_white_patch_3L10N=\"ReLU_50_white_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# ReLU_95_full_black_3L10N=\"ReLU_95_full_black_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "## 3L10N\n",
        "ReLU_95_white_patch_3L10N=\"ReLU_95_white_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "ReLU_no_patch_3L10N=\"ReLU_no_patch_no_extra_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "ReLU_no_patch_5_percent_3L10N=\"ReLU_no_patch_no_extra_data_train_test_5_per_data_lr_.0001_epoch_1k_seed_365.npz\" #check .001 or .0001\n",
        "# ReLU_no_patch_5_percent_2k_3L10N=\"ReLU_no_patch_no_extra_data_train_test_5_per_data_lr_.001_epoch_2k_seed_365.npz\"\n",
        "\n",
        "## 3L100N\n",
        "ReLU_95_white_patch_3L100N=\"ReLU_95_white_patch_no_extra_data_3L100N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "ReLU_no_patch_3L100N=\"ReLU_no_patch_no_extra_data_3L100N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "ReLU_no_patch_5_percent_3L100N=\"ReLU_no_patch_no_extra_data_train_test_5_per_data_3L100N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "## 3L5N\n",
        "ReLU_95_white_patch_3L5N=\"ReLU_95_white_patch_no_extra_data_3L5N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "ReLU_no_patch_3L5N=\"ReLU_no_patch_no_extra_data_3L5N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "ReLU_no_patch_5_percent_3L5N=\"ReLU_no_patch_no_extra_data_train_test_5_per_data_3L5N_lr_.0001_epoch_1k_seed_365.npz\""
      ],
      "metadata": {
        "id": "uOR2R5gVbufX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Change file name to visualize accordingly\n",
        "file_name_load=file_path+DLGN_95_white_patch_3L5N\n",
        "dict_data = load(file_name_load,allow_pickle=True)\n",
        "losses=dict_data['arr_0']\n",
        "model_store=dict_data['arr_1']"
      ],
      "metadata": {
        "id": "ECZ3ro0Fa1su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Nodes Visualization**"
      ],
      "metadata": {
        "id": "u92IOHHTdBQ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **New Idea based on node active for each class**"
      ],
      "metadata": {
        "id": "mbkJ7ioj3HNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating dataloaders for both training and testing to load all the images\n",
        "trainloader_all = torch.utils.data.DataLoader(trainset,batch_size = trainset.data.shape[0],\n",
        "                                        shuffle=True)\n",
        "testloader_all = torch.utils.data.DataLoader(testset,batch_size = testset.data.shape[0],\n",
        "                                      shuffle=False)\n",
        "\n",
        "trainiter_full = iter(trainloader_all)\n",
        "train_images_all,train_labels_all = next(trainiter_full)\n",
        "\n",
        "testiter_full = iter(testloader_all)\n",
        "test_images_all,test_labels_all = next(testiter_full)\n"
      ],
      "metadata": {
        "id": "ZXFDS3pe343Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nodes_to_train():\n",
        "  nodes_to_train_store=[]\n",
        "  for i in range(num_of_classes):\n",
        "    Query_img=train_images_all[(train_labels_all==i)]\n",
        "    Query_img_comp=train_images_all[(train_labels_all==10+i)]\n",
        "    Query_img_flatten=Query_img.view(Query_img.shape[0],-1)\n",
        "    Query_img_comp_flatten=Query_img_comp.view(Query_img_comp.shape[0],-1)\n",
        "    num_models_to_store = int(round(len(model_store)/3))+1\n",
        "    node_activity_score=np.zeros((num_models_to_store,num_hidden_layers,num_hidden_nodes[0]))\n",
        "    index=0\n",
        "    for epoch_index in range(len(model_store)):\n",
        "      if(epoch_index%3==0 or epoch_index==len(model_store)-1):\n",
        "        effective_weights, effective_biases = model_store[epoch_index].return_gating_functions()\n",
        "        for layer_num in range(num_hidden_layers):\n",
        "          for node_num in range(num_hidden_nodes[layer_num]):\n",
        "            weight = effective_weights[layer_num][node_num].data.numpy()\n",
        "            bias = effective_biases[layer_num][node_num].data.numpy()\n",
        "            EW_Q = ((Query_img_flatten@weight.T)+bias)>0\n",
        "            EW_Q=EW_Q.sum().item()/Query_img_flatten.shape[0]\n",
        "            EW_Q_comp = ((Query_img_comp_flatten@weight.T)+bias)>0\n",
        "            EW_Q_comp=EW_Q_comp.sum().item()/Query_img_comp_flatten.shape[0]\n",
        "            node_activity_score[index][layer_num][node_num]=round((EW_Q-EW_Q_comp),3)\n",
        "        index=index+1\n",
        "    nodes_to_train_store.append(np.argwhere(abs(node_activity_score[-1,:,:])>0.4))\n",
        "  return nodes_to_train_store"
      ],
      "metadata": {
        "id": "poeRBo45343a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nodes_to_train_store=nodes_to_train()"
      ],
      "metadata": {
        "id": "25BkeRWf343b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nodes_to_train_store"
      ],
      "metadata": {
        "id": "Zf3tUgxh343c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Query_img=train_images_all[(train_labels_all==1)]\n",
        "Query_img_comp=train_images_all[(train_labels_all==10)]"
      ],
      "metadata": {
        "id": "YRFjLe1R343c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matplotlib_imshow(torchvision.utils.make_grid(Query_img[0]),True)"
      ],
      "metadata": {
        "id": "L6ensv5L343d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matplotlib_imshow(torchvision.utils.make_grid(Query_img_comp[0]),True)"
      ],
      "metadata": {
        "id": "LGe-ZdtA343d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Query_img_flatten=Query_img.view(Query_img.shape[0],-1)\n",
        "Query_img_comp_flatten=Query_img_comp.view(Query_img_comp.shape[0],-1)"
      ],
      "metadata": {
        "id": "0__c7uj4343e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Query_img_flatten.shape"
      ],
      "metadata": {
        "id": "D6O5u0rY343e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Query_img_comp_flatten.shape"
      ],
      "metadata": {
        "id": "cexl7Z_O343e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_models_to_store = int(round(len(model_store)/3))+1"
      ],
      "metadata": {
        "id": "iOD86h-j343f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# node_activity_score=np.zeros((num_models_to_store,num_hidden_layers,num_hidden_nodes[0]))\n",
        "# index=0\n",
        "# for epoch_index in range(len(model_store)):\n",
        "#   if(epoch_index%3==0 or epoch_index==len(model_store)-1):\n",
        "#     effective_weights, effective_biases = model_store[epoch_index].return_gating_functions()\n",
        "#     for layer_num in range(num_hidden_layers):\n",
        "#       for node_num in range(num_hidden_nodes[layer_num]):\n",
        "#         weight = effective_weights[layer_num][node_num].data.numpy()\n",
        "#         EW_Q = Query_img_flatten@weight.T\n",
        "#         EW_Q_comp = Query_img_comp_flatten@weight.T\n",
        "#         node_activity_score[index][layer_num][node_num]=EW_Q-EW_Q_comp\n",
        "#     index=index+1"
      ],
      "metadata": {
        "id": "KEqkZFIO343f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_activity_score=np.zeros((num_models_to_store,num_hidden_layers,num_hidden_nodes[0]))\n",
        "index=0\n",
        "for epoch_index in range(len(model_store)):\n",
        "  if(epoch_index%3==0 or epoch_index==len(model_store)-1):\n",
        "    effective_weights, effective_biases = model_store[epoch_index].return_gating_functions()\n",
        "    for layer_num in range(num_hidden_layers):\n",
        "      for node_num in range(num_hidden_nodes[layer_num]):\n",
        "        weight = effective_weights[layer_num][node_num].data.numpy()\n",
        "        bias = effective_biases[layer_num][node_num].data.numpy()\n",
        "        EW_Q = ((Query_img_flatten@weight.T)+bias)>0\n",
        "        EW_Q=EW_Q.sum().item()/Query_img_flatten.shape[0]\n",
        "        EW_Q_comp = ((Query_img_comp_flatten@weight.T)+bias)>0\n",
        "        EW_Q_comp=EW_Q_comp.sum().item()/Query_img_comp_flatten.shape[0]\n",
        "        node_activity_score[index][layer_num][node_num]=round((EW_Q-EW_Q_comp),3)\n",
        "    index=index+1"
      ],
      "metadata": {
        "id": "hYqS_w1Y343f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_activity_score_layer0=node_activity_score[:,0,:]\n",
        "node_activity_score_layer1=node_activity_score[:,1,:]\n",
        "node_activity_score_layer2=node_activity_score[:,2,:]"
      ],
      "metadata": {
        "id": "iuPi2lnt343f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_count_store = [0, 9,36,81, 144,225,324, 441,576,729, 900,961]"
      ],
      "metadata": {
        "id": "f5JELVSJ343g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_activity_score_layer0_table = pd.DataFrame(data = node_activity_score_layer0,\n",
        "                        index = [\"E_0\", \"E_9\",\"E_36\",\"E_81\", \"E_144\",\"E_225\",\"E_324\", \"E_441\",\"E_576\",\"E_729\", \"E_900\",\"E_961\"],\n",
        "                        columns = [\"Node_0\",\"Node_1\", \"Node_2\",\"Node_3\",\"Node_4\", \"Node_5\",\"Node_6\",\"Node_7\", \"Node_8\",\"Node_9\"])\n",
        "                        # columns = [\"Node_0\",\"Node_1\", \"Node_2\",\"Node_3\",\"Node_4\"])\n",
        "\n",
        "node_activity_score_layer0_table.style.set_caption(\"Layer 0\")\n"
      ],
      "metadata": {
        "id": "g17toRk6343g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "for node_num in range(num_hidden_nodes[0]):\n",
        "  plt.plot(epoch_count_store,node_activity_score_layer0.T[node_num],label=\"Node_\"+str(node_num))\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Node Activity Score')\n",
        "plt.title('Layer 0')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3eoIkg--343g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_activity_score_layer1_table = pd.DataFrame(data = node_activity_score_layer1,\n",
        "                        index = [\"E_0\", \"E_9\",\"E_36\",\"E_81\", \"E_144\",\"E_225\",\"E_324\", \"E_441\",\"E_576\",\"E_729\", \"E_900\",\"E_961\"],\n",
        "                        columns = [\"Node_0\",\"Node_1\", \"Node_2\",\"Node_3\",\"Node_4\", \"Node_5\",\"Node_6\",\"Node_7\", \"Node_8\",\"Node_9\"])\n",
        "                        # columns = [\"Node_0\",\"Node_1\", \"Node_2\",\"Node_3\",\"Node_4\"])\n",
        "\n",
        "node_activity_score_layer1_table.style.set_caption(\"Layer 1\")"
      ],
      "metadata": {
        "id": "YrgmmVTk343g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "for node_num in range(num_hidden_nodes[0]):\n",
        "  plt.plot(epoch_count_store,node_activity_score_layer1.T[node_num],label=\"Node_\"+str(node_num))\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Node Activity Score')\n",
        "plt.title('Layer 1')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IOxkVoC_343h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_activity_score_layer2_table = pd.DataFrame(data = node_activity_score_layer2,\n",
        "                        index = [\"E_0\", \"E_9\",\"E_36\",\"E_81\", \"E_144\",\"E_225\",\"E_324\", \"E_441\",\"E_576\",\"E_729\", \"E_900\",\"E_961\"],\n",
        "                        columns = [\"Node_0\",\"Node_1\", \"Node_2\",\"Node_3\",\"Node_4\", \"Node_5\",\"Node_6\",\"Node_7\", \"Node_8\",\"Node_9\"])\n",
        "                        # columns = [\"Node_0\",\"Node_1\", \"Node_2\",\"Node_3\",\"Node_4\"])\n",
        "node_activity_score_layer2_table.style.set_caption(\"Layer 2\")"
      ],
      "metadata": {
        "id": "-X36hw1r343h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "for node_num in range(num_hidden_nodes[0]):\n",
        "  plt.plot(epoch_count_store,node_activity_score_layer2.T[node_num],label=\"Node_\"+str(node_num))\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Node Activity Score')\n",
        "plt.title('Layer 2')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RYfMuIGj343h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Generating Query and Query complement(Implementing EW_Q-EW_Q_comp)**"
      ],
      "metadata": {
        "id": "aVvxBX0qPXgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Query_img=torch.zeros(1,trainset.data.shape[1],trainset.data.shape[2],dtype=torch.float32)-1\n",
        "Query_img_comp=torch.zeros(1,trainset.data.shape[1],trainset.data.shape[2],dtype=torch.float32)+1\n",
        "Query_img[0][:,0:4]=1\n",
        "Query_img[0][:,-4:]=1\n",
        "Query_img_comp[0][:,0:4]=-1\n",
        "Query_img_comp[0][:,-4:]=-1"
      ],
      "metadata": {
        "id": "WOLAA10ArjDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "trainset.data.shape #torch.Size([60000, 28, 28])\n",
        "images.shape #torch.Size([64, 1, 28, 28])\n",
        "images_test = images.view(images.shape[0],-1)\n",
        "images_test.shape #torch.Size([64, 784])\n",
        "Query_img_flatten.shape #torch.Size([1, 784])\n",
        "Query_img_comp_flatten.shape #torch.Size([1, 784])\n",
        "'''"
      ],
      "metadata": {
        "id": "DESmnLYXDxUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matplotlib_imshow(torchvision.utils.make_grid(Query_img),True)"
      ],
      "metadata": {
        "id": "Hg0a2sOls9qL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matplotlib_imshow(torchvision.utils.make_grid(Query_img_comp),True)"
      ],
      "metadata": {
        "id": "j1XIu4YSrfnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Query_img_flatten=Query_img.view(Query_img.shape[0],-1)\n",
        "Query_img_comp_flatten=Query_img_comp.view(Query_img_comp.shape[0],-1)"
      ],
      "metadata": {
        "id": "LkHPvDenLIEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Query_img_flatten.shape"
      ],
      "metadata": {
        "id": "2Z_9EMM5LmCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Query_img_comp_flatten.shape"
      ],
      "metadata": {
        "id": "TqitoWKoP8Xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_models_to_store = int(round(len(model_store)/3))+1"
      ],
      "metadata": {
        "id": "SI8Qb2mVgEl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_activity_score=np.zeros((num_models_to_store,num_hidden_layers,num_hidden_nodes[0]))\n",
        "index=0\n",
        "for epoch_index in range(len(model_store)):\n",
        "  if(epoch_index%3==0 or epoch_index==len(model_store)-1):\n",
        "    effective_weights, effective_biases = model_store[epoch_index].return_gating_functions()\n",
        "    for layer_num in range(num_hidden_layers):\n",
        "      for node_num in range(num_hidden_nodes[layer_num]):\n",
        "        weight = effective_weights[layer_num][node_num].data.numpy()\n",
        "        EW_Q = Query_img_flatten@weight.T\n",
        "        EW_Q_comp = Query_img_comp_flatten@weight.T\n",
        "        node_activity_score[index][layer_num][node_num]=EW_Q-EW_Q_comp\n",
        "    index=index+1"
      ],
      "metadata": {
        "id": "z1LkewvWF1AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_activity_score_layer0=node_activity_score[:,0,:]\n",
        "node_activity_score_layer1=node_activity_score[:,1,:]\n",
        "node_activity_score_layer2=node_activity_score[:,2,:]"
      ],
      "metadata": {
        "id": "c6UWk80_UPw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_count_store = [0, 9,36,81, 144,225,324, 441,576,729, 900,961]"
      ],
      "metadata": {
        "id": "wfHFx0s1agVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_activity_score_layer0_table = pd.DataFrame(data = node_activity_score_layer0,\n",
        "                        index = [\"E_0\", \"E_9\",\"E_36\",\"E_81\", \"E_144\",\"E_225\",\"E_324\", \"E_441\",\"E_576\",\"E_729\", \"E_900\",\"E_961\"],\n",
        "                        columns = [\"Node_0\",\"Node_1\", \"Node_2\",\"Node_3\",\"Node_4\", \"Node_5\",\"Node_6\",\"Node_7\", \"Node_8\",\"Node_9\"])\n",
        "                        # columns = [\"Node_0\",\"Node_1\", \"Node_2\",\"Node_3\",\"Node_4\"])\n",
        "\n",
        "node_activity_score_layer0_table.style.set_caption(\"Layer 0\")\n"
      ],
      "metadata": {
        "id": "LVshz0X-WY68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "for node_num in range(num_hidden_nodes[0]):\n",
        "  plt.plot(epoch_count_store,node_activity_score_layer0.T[node_num],label=\"Node_\"+str(node_num))\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Node Activity Score')\n",
        "plt.title('Layer 0')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mVKsaPonmVwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_activity_score_layer1_table = pd.DataFrame(data = node_activity_score_layer1,\n",
        "                        index = [\"E_0\", \"E_9\",\"E_36\",\"E_81\", \"E_144\",\"E_225\",\"E_324\", \"E_441\",\"E_576\",\"E_729\", \"E_900\",\"E_961\"],\n",
        "                        columns = [\"Node_0\",\"Node_1\", \"Node_2\",\"Node_3\",\"Node_4\", \"Node_5\",\"Node_6\",\"Node_7\", \"Node_8\",\"Node_9\"])\n",
        "                        # columns = [\"Node_0\",\"Node_1\", \"Node_2\",\"Node_3\",\"Node_4\"])\n",
        "\n",
        "node_activity_score_layer1_table.style.set_caption(\"Layer 1\")"
      ],
      "metadata": {
        "id": "PPbRG1vqlZ5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "for node_num in range(num_hidden_nodes[0]):\n",
        "  plt.plot(epoch_count_store,node_activity_score_layer1.T[node_num],label=\"Node_\"+str(node_num))\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Node Activity Score')\n",
        "plt.title('Layer 1')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sZdKjI68puyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_activity_score_layer2_table = pd.DataFrame(data = node_activity_score_layer2,\n",
        "                        index = [\"E_0\", \"E_9\",\"E_36\",\"E_81\", \"E_144\",\"E_225\",\"E_324\", \"E_441\",\"E_576\",\"E_729\", \"E_900\",\"E_961\"],\n",
        "                        columns = [\"Node_0\",\"Node_1\", \"Node_2\",\"Node_3\",\"Node_4\", \"Node_5\",\"Node_6\",\"Node_7\", \"Node_8\",\"Node_9\"])\n",
        "                        # columns = [\"Node_0\",\"Node_1\", \"Node_2\",\"Node_3\",\"Node_4\"])\n",
        "node_activity_score_layer2_table.style.set_caption(\"Layer 2\")"
      ],
      "metadata": {
        "id": "YwPR2Ds6lbM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "for node_num in range(num_hidden_nodes[0]):\n",
        "  plt.plot(epoch_count_store,node_activity_score_layer2.T[node_num],label=\"Node_\"+str(node_num))\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Node Activity Score')\n",
        "plt.title('Layer 2')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q8_mnk5ep3v3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ULQ3I_WoPuPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Node Activity for Patched and Unpatched images**"
      ],
      "metadata": {
        "id": "KpRKSzm6PxuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating dataloaders for both training and testing to load all the images\n",
        "trainloader_all = torch.utils.data.DataLoader(trainset,batch_size = trainset.data.shape[0],\n",
        "                                        shuffle=True)\n",
        "testloader_all = torch.utils.data.DataLoader(testset,batch_size = testset.data.shape[0],\n",
        "                                      shuffle=False)\n",
        "\n",
        "trainiter_full = iter(trainloader_all)\n",
        "train_images_all,train_labels_all = next(trainiter_full)\n",
        "\n",
        "testiter_full = iter(testloader_all)\n",
        "test_images_all,test_labels_all = next(testiter_full)\n"
      ],
      "metadata": {
        "id": "FvdiQ3b7Z692"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matplotlib_imshow(torchvision.utils.make_grid(test_images_all[0:64]),True)"
      ],
      "metadata": {
        "id": "i9hiojsxE_jG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_all_flatten=train_images_all.view(train_images_all.shape[0],-1)\n",
        "test_images_all_flatten=test_images_all.view(test_images_all.shape[0],-1)"
      ],
      "metadata": {
        "id": "NtOEuX3ePuDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_models_to_store = int(round(len(model_store)/3))+1"
      ],
      "metadata": {
        "id": "GHlWzee1Puzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Get_node_activity(images_all_flatten,labels_all):\n",
        "  patched_img_node_activity_score=np.zeros((num_models_to_store,num_hidden_layers,num_hidden_nodes[0]))\n",
        "  unpatched_img_node_activity_score=np.zeros((num_models_to_store,num_hidden_layers,num_hidden_nodes[0]))\n",
        "\n",
        "  index=0\n",
        "  for epoch_index in range(len(model_store)):\n",
        "    if(epoch_index%3==0 or epoch_index==len(model_store)-1):\n",
        "      effective_weights, effective_biases = model_store[epoch_index].return_gating_functions()\n",
        "      for layer_num in range(num_hidden_layers):\n",
        "        for node_num in range(num_hidden_nodes[layer_num]):\n",
        "          weight = effective_weights[layer_num][node_num].data.numpy() #eff_weight of a node\n",
        "          bias = effective_biases[layer_num][node_num].data.numpy() #eff_bias of a node\n",
        "\n",
        "          EW_image = ((images_all_flatten@weight.T) + bias)>0 # shape: 60000-->training data\n",
        "          patched_idx = (labels_all>9) # shape: 60000-->training data (index of all patched imgs)\n",
        "          num_patched_imgs = patched_idx.sum().item() #total num of patched images\n",
        "\n",
        "          unpatched_idx = (labels_all<10) # shape: 60000-->training data (index of all unpatched imgs)\n",
        "          num_unpatched_imgs = unpatched_idx.sum().item() #total num of unpatched images\n",
        "\n",
        "          num_patched_actv = (EW_image & patched_idx).sum().item() #total num of patched imgs that are on for the node\n",
        "          num_unpatched_actv = (EW_image & unpatched_idx).sum().item() #total num of unpatched imgs that are on for the node\n",
        "\n",
        "          patched_img_node_activity_score[index][layer_num][node_num]= num_patched_actv/num_patched_imgs #storing frac of patched imgs active\n",
        "          unpatched_img_node_activity_score[index][layer_num][node_num]=num_unpatched_actv/num_unpatched_imgs #storing frac of unpatched imgs active\n",
        "      index=index+1\n",
        "  return patched_img_node_activity_score,unpatched_img_node_activity_score"
      ],
      "metadata": {
        "id": "GDWNPgUiPuzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Change the variables for train or test image loading**"
      ],
      "metadata": {
        "id": "3HYTo5PSM_Xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images_all_flatten=test_images_all_flatten #train_images_all_flatten/test_images_all_flatten\n",
        "labels_all=test_labels_all #train_labels_all/test_labels_all"
      ],
      "metadata": {
        "id": "7B_VdmogM1Dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Patched/unpatched node activity store**"
      ],
      "metadata": {
        "id": "sOzoVUK_NXnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patched_img_node_activity_score,unpatched_img_node_activity_score = Get_node_activity(images_all_flatten,labels_all)\n",
        "\n",
        "patched_img_node_activity_score_layer0=patched_img_node_activity_score[:,0,:]\n",
        "patched_img_node_activity_score_layer1=patched_img_node_activity_score[:,1,:]\n",
        "patched_img_node_activity_score_layer2=patched_img_node_activity_score[:,2,:]\n",
        "\n",
        "unpatched_img_node_activity_score_layer0=unpatched_img_node_activity_score[:,0,:]\n",
        "unpatched_img_node_activity_score_layer1=unpatched_img_node_activity_score[:,1,:]\n",
        "unpatched_img_node_activity_score_layer2=unpatched_img_node_activity_score[:,2,:]"
      ],
      "metadata": {
        "id": "MmaL1i6cPuzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_count_store = [0, 9,36,81, 144,225,324, 441,576,729, 900,961]"
      ],
      "metadata": {
        "id": "lV0VAesQPuze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns5 = [\"Node_0\",\"Node_1\", \"Node_2\",\"Node_3\",\"Node_4\"]\n",
        "columns10 = [\"Node_0\",\"Node_1\", \"Node_2\",\"Node_3\",\"Node_4\", \"Node_5\",\"Node_6\",\"Node_7\", \"Node_8\",\"Node_9\"]\n",
        "if(num_hidden_nodes[0]==5):\n",
        "  columns=columns5\n",
        "if(num_hidden_nodes[0]==10):\n",
        "  columns=columns10"
      ],
      "metadata": {
        "id": "KirXVYahp1vT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Patched Image Layer 0**"
      ],
      "metadata": {
        "id": "DeKrm0mvNiIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patched_img_node_activity_score_layer0_table = pd.DataFrame(data = patched_img_node_activity_score_layer0,\n",
        "                        index = [\"E_0\", \"E_9\",\"E_36\",\"E_81\", \"E_144\",\"E_225\",\"E_324\", \"E_441\",\"E_576\",\"E_729\", \"E_900\",\"E_961\"],\n",
        "                        columns = columns)\n",
        "\n",
        "patched_img_node_activity_score_layer0_table.style.set_caption(\"Layer 0 Patched Img\")\n"
      ],
      "metadata": {
        "id": "Sa_sjz51Puzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "for node_num in range(num_hidden_nodes[0]):\n",
        "  plt.plot(epoch_count_store,patched_img_node_activity_score_layer0.T[node_num],label=\"Node_\"+str(node_num))\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Patched Img Node Activity Score')\n",
        "plt.title('Layer 0')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bVjZglwIPuzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unpatched Image Layer 0**"
      ],
      "metadata": {
        "id": "KA8jI6wDNp5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unpatched_img_node_activity_score_layer0_table = pd.DataFrame(data = unpatched_img_node_activity_score_layer0,\n",
        "                        index = [\"E_0\", \"E_9\",\"E_36\",\"E_81\", \"E_144\",\"E_225\",\"E_324\", \"E_441\",\"E_576\",\"E_729\", \"E_900\",\"E_961\"],\n",
        "                        columns = columns)\n",
        "\n",
        "unpatched_img_node_activity_score_layer0_table.style.set_caption(\"Layer 0 Unpatched Img\")\n"
      ],
      "metadata": {
        "id": "TmzmLT8B_CM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "for node_num in range(num_hidden_nodes[0]):\n",
        "  plt.plot(epoch_count_store,unpatched_img_node_activity_score_layer0.T[node_num],label=\"Node_\"+str(node_num))\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Unpatched Img Node Activity Score')\n",
        "plt.title('Layer 0')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QdSaGknz_0pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Patched Image Layer 1**"
      ],
      "metadata": {
        "id": "E2M7qZj7NuAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patched_img_node_activity_score_layer1_table = pd.DataFrame(data = patched_img_node_activity_score_layer1,\n",
        "                        index = [\"E_0\", \"E_9\",\"E_36\",\"E_81\", \"E_144\",\"E_225\",\"E_324\", \"E_441\",\"E_576\",\"E_729\", \"E_900\",\"E_961\"],\n",
        "                        columns = columns)\n",
        "\n",
        "patched_img_node_activity_score_layer1_table.style.set_caption(\"Layer 1 Patched Img\")\n"
      ],
      "metadata": {
        "id": "Tv9rB7hnAF0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "for node_num in range(num_hidden_nodes[0]):\n",
        "  plt.plot(epoch_count_store,patched_img_node_activity_score_layer1.T[node_num],label=\"Node_\"+str(node_num))\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Patched Img Node Activity Score')\n",
        "plt.title('Layer 1')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xh2L3z2aAF0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unpatched Image Layer 1**"
      ],
      "metadata": {
        "id": "3uM-RT8iNzIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unpatched_img_node_activity_score_layer1_table = pd.DataFrame(data = unpatched_img_node_activity_score_layer1,\n",
        "                        index = [\"E_0\", \"E_9\",\"E_36\",\"E_81\", \"E_144\",\"E_225\",\"E_324\", \"E_441\",\"E_576\",\"E_729\", \"E_900\",\"E_961\"],\n",
        "                        columns = columns)\n",
        "\n",
        "unpatched_img_node_activity_score_layer1_table.style.set_caption(\"Layer 1 Unpatched Img\")"
      ],
      "metadata": {
        "id": "bGdQ-O7uAF0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "for node_num in range(num_hidden_nodes[0]):\n",
        "  plt.plot(epoch_count_store,unpatched_img_node_activity_score_layer1.T[node_num],label=\"Node_\"+str(node_num))\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Unpatched Img Node Activity Score')\n",
        "plt.title('Layer 1')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ts5ew4J6AF0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Patched Image Layer 2**"
      ],
      "metadata": {
        "id": "olie2RjlN5Xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patched_img_node_activity_score_layer2_table = pd.DataFrame(data = patched_img_node_activity_score_layer2,\n",
        "                        index = [\"E_0\", \"E_9\",\"E_36\",\"E_81\", \"E_144\",\"E_225\",\"E_324\", \"E_441\",\"E_576\",\"E_729\", \"E_900\",\"E_961\"],\n",
        "                        columns = columns)\n",
        "\n",
        "patched_img_node_activity_score_layer2_table.style.set_caption(\"Layer 2 Patched Img\")\n"
      ],
      "metadata": {
        "id": "gGB-jeh2AG2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "for node_num in range(num_hidden_nodes[0]):\n",
        "  plt.plot(epoch_count_store,patched_img_node_activity_score_layer2.T[node_num],label=\"Node_\"+str(node_num))\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Patched Img Node Activity Score')\n",
        "plt.title('Layer 2')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mj3XDOCOAG3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unpatched Image Layer 2**"
      ],
      "metadata": {
        "id": "fO1myw44N-6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unpatched_img_node_activity_score_layer2_table = pd.DataFrame(data = unpatched_img_node_activity_score_layer2,\n",
        "                        index = [\"E_0\", \"E_9\",\"E_36\",\"E_81\", \"E_144\",\"E_225\",\"E_324\", \"E_441\",\"E_576\",\"E_729\", \"E_900\",\"E_961\"],\n",
        "                        columns = columns)\n",
        "\n",
        "unpatched_img_node_activity_score_layer2_table.style.set_caption(\"Layer 2 Unpatched Img\")"
      ],
      "metadata": {
        "id": "MNczsa1kAG3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "for node_num in range(num_hidden_nodes[0]):\n",
        "  plt.plot(epoch_count_store,unpatched_img_node_activity_score_layer2.T[node_num],label=\"Node_\"+str(node_num))\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Unpatched Img Node Activity Score')\n",
        "plt.title('Layer 2')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AXvUTuX5AG3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Error Plots**"
      ],
      "metadata": {
        "id": "ILVbj5xZNvXA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saved error files**"
      ],
      "metadata": {
        "id": "qA3qidTqN_7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Saved_models_latest\n",
        "\n",
        "#DLGN\n",
        "error_dlgn_50_white_patch_3L10N = \"Error_DLGN_50_white_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "error_dlgn_50_full_black_3L10N = \"Error_DLGN_50_full_black_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "error_dlgn_95_full_black_3L10N = \"Error_DLGN_95_full_black_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "error_file=\"error_test_DLGN.npz\"\n",
        "\n",
        "#3L10N\n",
        "error_dlgn_no_patch_3L10N = \"Error_DLGN_no_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "error_dlgn_no_patch_5_perc_3L10N = \"Error_DLGN_no_patch_no_extra_data_train_test_5_per_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "error_dlgn_95_white_patch_3L10N = \"Error_DLGN_95_white_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "#3L100N\n",
        "error_dlgn_no_patch_3L100N = \"Error_DLGN_no_patch_no_extra_data_3L100N_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "error_dlgn_no_patch_5_perc_3L100N = \"Error_DLGN_no_patch_no_extra_data_train_test_5_per_data_3L100N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "error_dlgn_95_white_patch_3L100N = \"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "#3L5N\n",
        "error_dlgn_no_patch_3L5N = \"Error_DLGN_no_patch_no_extra_data_3L5N_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "error_dlgn_no_patch_5_perc_3L5N = \"Error_DLGN_no_patch_no_extra_data_train_test_5_per_data_3L5N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "error_dlgn_95_white_patch_3L5N = \"Error_DLGN_95_white_patch_no_extra_data_3L5N_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "'''\n",
        "New Algo\n",
        "'''\n",
        "error_dlgn_95_white_patch_3L10N_new_algo = \"Error_DLGN_95_white_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365_new_algo.npz\"\n",
        "error_dlgn_no_patch_5_perc_3L10N = \"Error_DLGN_no_patch_no_extra_data_train_test_5_per_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "error_dlgn_no_patch_3L10N = \"Error_DLGN_no_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "\n",
        "'''\n",
        "Saved_models_25may\n",
        "'''\n",
        "#100 nodes\n",
        "'''\n",
        "100 Epochs\n",
        "'''\n",
        "\n",
        "error_dlgn_95_white_patch_lr_001_epoch_100_3L100N=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_100_seed_365_beta_20.npz\"\n",
        "error_dlgn_no_patch_lr_001_epoch_100_3L100N=\"Error_DLGN_no_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_100_seed_365_beta_20.npz\"\n",
        "error_dlgn_no_patch_5_perc_lr_001_epoch_100_3L100N=\"Error_DLGN_no_patch_no_extra_data_train_test_5_per_data_3L100N_lr_.001_epoch_100_seed_365_beta_20.npz\"\n",
        "error_dlgn_95_white_patch_lr_001_epoch_100_3L100N_new_algo=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_100_seed_365_beta_20_new_algo_10_15.npz\"\n",
        "\n",
        "'''\n",
        "225 Epochs\n",
        "'''\n",
        "\n",
        "error_dlgn_95_white_patch_lr_001_epoch_225_3L100N=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_225_seed_365_beta_20.npz\"\n",
        "error_dlgn_no_patch_lr_001_epoch_225_3L100N=\"Error_DLGN_no_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_225_seed_365_beta_20.npz\"\n",
        "error_dlgn_no_patch_5_perc_lr_001_epoch_225_3L100N=\"Error_DLGN_no_patch_no_extra_data_train_test_5_per_data_3L100N_lr_.001_epoch_225_seed_365_beta_20.npz\"\n",
        "error_dlgn_95_white_patch_lr_001_epoch_225_3L100N_new_algo_2_10=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_225_seed_365_beta_20_new_algo_2_10.npz\"\n",
        "error_dlgn_95_white_patch_lr_001_epoch_225_3L100N_new_algo_10_15=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_225_seed_365_beta_20_new_algo_10_15.npz\"\n",
        "error_dlgn_95_white_patch_lr_001_epoch_225_3L100N_new_algo_2_10_all_node_freeze=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_225_seed_365_beta_20_new_algo_2_10_all_node_freeze.npz\"\n",
        "error_dlgn_95_white_patch_lr_001_epoch_225_3L100N_new_algo_10_15_all_node_freeze=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_225_seed_365_beta_20_new_algo_10_15_all_node_freeze.npz\"\n",
        "\n",
        "\n",
        "'''\n",
        "225 Epochs Beta 100\n",
        "'''\n",
        "\n",
        "error_dlgn_95_white_patch_lr_001_epoch_225_3L100N_beta_100=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_225_seed_365_beta_100.npz\"\n",
        "error_dlgn_no_patch_lr_001_epoch_225_3L100N_beta_100=\"Error_DLGN_no_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_225_seed_365_beta_100.npz\"\n",
        "error_dlgn_no_patch_5_perc_lr_001_epoch_225_3L100N_beta_100=\"Error_DLGN_no_patch_no_extra_data_train_test_5_per_data_3L100N_lr_.001_epoch_225_seed_365_beta_100.npz\"\n",
        "error_dlgn_95_white_patch_lr_001_epoch_225_3L100N_new_algo_2_10_beta_100=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_225_seed_365_beta_100_new_algo_2_10.npz\"\n",
        "error_dlgn_95_white_patch_lr_001_epoch_225_3L100N_new_algo_10_15_beta_100=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_225_seed_365_beta_100_new_algo_10_15.npz\"\n",
        "error_dlgn_95_white_patch_lr_001_epoch_225_3L100N_new_algo_2_10_beta_100_all_node_freeze=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_225_seed_365_beta_100_new_algo_2_10_all_node_freeze.npz\"\n",
        "error_dlgn_95_white_patch_lr_001_epoch_225_3L100N_new_algo_10_15_beta_100_all_node_freeze=\"Error_DLGN_95_white_patch_no_extra_data_3L100N_train_test_lr_.001_epoch_225_seed_365_beta_100_new_algo_10_15_all_node_freeze.npz\"\n",
        "\n",
        "\n",
        "#ReLU\n",
        "# error_relu_50_white_patch_3L10N = \"Error_ReLU_50_white_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_relu_50_full_black_3L10N = \"Error_ReLU_50_full_black_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "# error_relu_95_full_black_3L10N = \"Error_ReLU_95_full_black_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "#3L10N\n",
        "error_relu_no_patch_3L10N = \"Error_ReLU_no_patch_no_extra_data_3L100N_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "error_relu_no_patch_5_perc_3L10N=\"Error_ReLU_no_patch_no_extra_data_train_test_5_per_data_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "# error_relu_no_patch_5_perc_2k_3L10N=\"Error_ReLU_no_patch_no_extra_data_train_test_5_per_data_lr_.001_epoch_2k_seed_365.npz\"\n",
        "# error_relu_no_patch_5_perc_3L10N_lr_0_001=\"Error_ReLU_no_patch_no_extra_data_train_test_lr_.001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "error_relu_95_white_patch_3L10N = \"Error_ReLU_95_white_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "#3L100N\n",
        "error_relu_no_patch_3L100N = \"Error_ReLU_no_patch_no_extra_data_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "error_relu_no_patch_5_perc_3L100N=\"Error_ReLU_no_patch_no_extra_data_train_test_5_per_data_3L100N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "error_relu_95_white_patch_3L100N = \"Error_ReLU_95_white_patch_no_extra_data_3L100N_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "\n",
        "#3L5N\n",
        "error_relu_no_patch_3L5N = \"Error_ReLU_no_patch_no_extra_data_3L5N_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "error_relu_no_patch_5_perc_3L5N=\"Error_ReLU_no_patch_no_extra_data_train_test_5_per_data_3L5N_lr_.0001_epoch_1k_seed_365.npz\"\n",
        "error_relu_95_white_patch_3L5N = \"Error_ReLU_95_white_patch_no_extra_data_3L5N_train_test_lr_.0001_epoch_1k_seed_365.npz\"\n"
      ],
      "metadata": {
        "id": "CelkKVEzrQUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title load error file\n",
        "def load_error_file(error_file):\n",
        "  file_name_load_error = file_path+error_file\n",
        "  dict_data_error = load(file_name_load_error,allow_pickle=True)\n",
        "\n",
        "  if(corrupted_train and corrupted_test):\n",
        "    max_epoch=dict_data_error['arr_0'].item()\n",
        "    max_acc=dict_data_error['arr_1'].item()\n",
        "    epoch_count=dict_data_error['arr_2']\n",
        "    train_error=dict_data_error['arr_3']\n",
        "    test_error=dict_data_error['arr_4']\n",
        "    train_corrupted_error=dict_data_error['arr_5']\n",
        "    train_real_error=dict_data_error['arr_6']\n",
        "    test_corrupted_error=dict_data_error['arr_7']\n",
        "    test_real_error=dict_data_error['arr_8']\n",
        "    return max_epoch,max_acc,epoch_count,train_error,test_error,train_corrupted_error,train_real_error,test_corrupted_error,test_real_error\n",
        "\n",
        "  elif(corrupted_train):\n",
        "    max_epoch=dict_data_error['arr_0'].item()\n",
        "    max_acc=dict_data_error['arr_1'].item()\n",
        "    epoch_count=dict_data_error['arr_2']\n",
        "    train_error=dict_data_error['arr_3']\n",
        "    test_error=dict_data_error['arr_4']\n",
        "    train_corrupted_error=dict_data_error['arr_5']\n",
        "    train_real_error=dict_data_error['arr_6']\n",
        "    return max_epoch,max_acc,epoch_count,train_error,test_error,train_corrupted_error,train_real_error\n",
        "\n",
        "  elif(corrupted_test):\n",
        "    max_epoch=dict_data_error['arr_0'].item()\n",
        "    max_acc=dict_data_error['arr_1'].item()\n",
        "    epoch_count=dict_data_error['arr_2']\n",
        "    train_error=dict_data_error['arr_3']\n",
        "    test_error=dict_data_error['arr_4']\n",
        "    test_corrupted_error=dict_data_error['arr_5']\n",
        "    test_real_error=dict_data_error['arr_6']\n",
        "    return max_epoch,max_acc,epoch_count,train_error,test_error,test_corrupted_error,test_real_error\n",
        "\n",
        "  else:\n",
        "    max_epoch=dict_data_error['arr_0'].item()\n",
        "    max_acc=dict_data_error['arr_1'].item()\n",
        "    epoch_count=dict_data_error['arr_2']\n",
        "    train_error=dict_data_error['arr_3']\n",
        "    test_error=dict_data_error['arr_4']\n",
        "    return max_epoch,max_acc,epoch_count,train_error,test_error\n",
        "\n"
      ],
      "metadata": {
        "id": "uFCwAyW_un4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Change the variables to plot different models**"
      ],
      "metadata": {
        "id": "uba1UqYZlhCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "error_dlgn_no_patch_5_perc=error_relu_no_patch_5_perc_3L5N\n",
        "error_dlgn_no_patch=error_relu_no_patch_3L5N\n",
        "error_dlgn_95_white_patch=error_relu_95_white_patch_3L5N"
      ],
      "metadata": {
        "id": "KamfCZ5Ik8Si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corrupted_train = False\n",
        "corrupted_test = False"
      ],
      "metadata": {
        "id": "NqiLBR5tJITl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_epoch_no_patch_5_perc,max_acc_no_patch_5_perc,epoch_count_no_patch_5_perc,train_error_no_patch_5_perc,test_error_no_patch_5_perc=load_error_file(error_dlgn_no_patch_5_perc)"
      ],
      "metadata": {
        "id": "VtwtraAy7zgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_epoch_no_patch,max_acc_no_patch,epoch_count_no_patch,train_error_no_patch,test_error_no_patch=load_error_file(error_dlgn_no_patch)"
      ],
      "metadata": {
        "id": "7KXenPiHI0mV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(max_acc_no_patch)\n",
        "print(max_epoch_no_patch**2)"
      ],
      "metadata": {
        "id": "TGOR6H1---4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Error File update**"
      ],
      "metadata": {
        "id": "wvzMWh53Nv37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#update the error file with error_files from Saved error files tab\n",
        "corrupted_train = True\n",
        "corrupted_test = True\n",
        "error_file = error_dlgn_95_white_patch"
      ],
      "metadata": {
        "id": "nogut9aeJZjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(corrupted_train and corrupted_test):\n",
        "  max_epoch,max_acc,epoch_count,train_error,test_error,train_corrupted_error,train_real_error,test_corrupted_error,test_real_error=load_error_file(error_file)\n",
        "\n",
        "elif(corrupted_train):\n",
        "  max_epoch,max_acc,epoch_count,train_error,test_error,train_corrupted_error,train_real_error=load_error_file(error_file)\n",
        "\n",
        "elif(corrupted_test):\n",
        "  max_epoch,max_acc,epoch_count,train_error,test_error,test_corrupted_error,test_real_error=load_error_file(error_file)\n",
        "\n",
        "else:\n",
        "  max_epoch,max_acc,epoch_count,train_error,test_error=load_error_file(error_file)\n",
        "\n"
      ],
      "metadata": {
        "id": "SW4meF9S8NMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(max_acc)\n",
        "print(max_epoch**2)"
      ],
      "metadata": {
        "id": "GNFGMJhySV9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot Train error curves**"
      ],
      "metadata": {
        "id": "46SHjcYoNeRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(epoch_count_no_patch**2,train_error_no_patch[:],'b',label=\"train_error\")\n",
        "plt.plot(epoch_count_no_patch_5_perc**2,train_error_no_patch_5_perc[:],'b--',label=\"train_error_5%\")\n",
        "\n",
        "if corrupted_train:\n",
        "  plt.plot(epoch_count**2,train_real_error[:],'r',label=\"train_real_error\")\n",
        "  plt.plot(epoch_count**2,train_corrupted_error[:],'g',label=\"train_corrupted_error\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Train Error')\n",
        "plt.title('Train error plot')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "My3JoKG-0p15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot Test error curves**"
      ],
      "metadata": {
        "id": "1X92xq1gNj1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(epoch_count_no_patch**2,test_error_no_patch[:],'b',label=\"test_error\")\n",
        "plt.plot(epoch_count_no_patch_5_perc**2,test_error_no_patch_5_perc[:],'b--',label=\"test_error_5%\")\n",
        "\n",
        "if corrupted_test:\n",
        "  plt.plot(epoch_count**2,test_real_error[:],'r',label=\"test_real_error\")\n",
        "  plt.plot(epoch_count**2,test_corrupted_error[:],'g',label=\"test_corrupted_error\")\n",
        "else:\n",
        "  plt.plot(test_error[:],label=\"test_real_error\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Test Error')\n",
        "plt.title('Test error plot')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OthaWei32kOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Overlap Kernel**"
      ],
      "metadata": {
        "id": "TU4QlAabBFG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Formatting the dataset**\n",
        "'''\n",
        "First of all create the dataset for making the overlap kernel\n",
        "We will use 10 class and 100 images for each class with 95 patched and 5 unpatched.\n",
        "So the overlap kernel will be a 1000*1000 matrix with 10 class and 100(95+5) images per class\n",
        "'''\n",
        "num_of_ovlp_imgs = 1000 #num of images in the overlap kernel matrix\n",
        "num_imgs_per_class = 100\n",
        "num_patched_imgs = 95\n",
        "num_unpatched_imgs = 5\n",
        "\n",
        "#Creating dataloaders for both training and testing to load all the images\n",
        "trainloader_all = torch.utils.data.DataLoader(trainset,batch_size = trainset.data.shape[0],\n",
        "                                        shuffle=True)\n",
        "testloader_all = torch.utils.data.DataLoader(testset,batch_size = testset.data.shape[0],\n",
        "                                      shuffle=False)\n",
        "\n",
        "trainiter_full = iter(trainloader_all)\n",
        "train_images_all,train_labels_all = next(trainiter_full)\n",
        "\n",
        "testiter_full = iter(testloader_all)\n",
        "test_images_all,test_labels_all = next(testiter_full)\n",
        "#Create a dataset containing 1000 images(1000,1,28,28) 10 class and 100 images for each class with 95 patched and 5 unpatched.\n",
        "\n",
        "ovrlp_krnl_imgs = torch.zeros(num_of_ovlp_imgs,train_images_all.shape[1],train_images_all.shape[2],train_images_all.shape[3],dtype=torch.float32)\n",
        "ovrlp_krnl_label = torch.zeros(num_of_ovlp_imgs,dtype=torch.int64)\n",
        "\n",
        "'''\n",
        "  Each class (95 patched images followed by 5 unpatched images for 10 classes in that order)\n",
        "'''\n",
        "#First store the patched data using 100xclass_num (0x100 to 0x100+95,1x100 to 1x100+95) like this then\n",
        "#store the unpatched data using 100xclass_num+95 (100x0+95 to 100x0+100,100x1 to 100x1+100) like this\n",
        "\n",
        "# for class_index in range(num_of_classes):\n",
        "#   ovrlp_krnl_imgs[num_imgs_per_class*class_index:num_imgs_per_class*class_index+num_patched_imgs]=train_images_all[train_labels_all==class_index+10][:num_patched_imgs] #storing the patched images\n",
        "#   ovrlp_krnl_label[num_imgs_per_class*class_index:num_imgs_per_class*class_index+num_patched_imgs]=train_labels_all[train_labels_all==class_index+10][:num_patched_imgs] #storing patched labels\n",
        "#   ovrlp_krnl_imgs[num_imgs_per_class*class_index+num_patched_imgs:num_imgs_per_class*class_index+num_imgs_per_class]=train_images_all[train_labels_all==class_index][:num_unpatched_imgs] #storing unpatched images\n",
        "#   ovrlp_krnl_label[num_imgs_per_class*class_index+num_patched_imgs:num_imgs_per_class*class_index+num_imgs_per_class]=train_labels_all[train_labels_all==class_index][:num_unpatched_imgs] #storing unpatched labels\n",
        "\n",
        "'''\n",
        "First put all the 95 patched images for all the classes so 950 then put all the patched images 50\n",
        "'''\n",
        "\n",
        "#First store all 950 patched data using 95xclass_num (95x0 to 95x0+95,95x1 to 95x1+95,...,95x9 to 95x9+95) like this then in the next for loop\n",
        "#store the unpatched data using 5xclass_num+95x10 (5x0+95x10 to 5x0+95x10+5,5x1+95x10 to 5x1+95x10+5,...,5x9+95x10 to 5x9+95x10+5) like this\n",
        "\n",
        "\n",
        "for class_index in range(num_of_classes):\n",
        "\n",
        "  ovrlp_krnl_imgs[num_patched_imgs*class_index:num_patched_imgs*class_index+num_patched_imgs]=test_images_all[test_labels_all==class_index+10][:num_patched_imgs] #storing the patched images\n",
        "  ovrlp_krnl_label[num_patched_imgs*class_index:num_patched_imgs*class_index+num_patched_imgs]=test_labels_all[test_labels_all==class_index+10][:num_patched_imgs] #storing patched labels\n",
        "\n",
        "for class_index in range(num_of_classes):\n",
        "\n",
        "  ovrlp_krnl_imgs[num_unpatched_imgs*class_index+(num_patched_imgs*num_of_classes):num_unpatched_imgs*class_index+(num_patched_imgs*num_of_classes+num_unpatched_imgs)]=test_images_all[test_labels_all==class_index][:num_unpatched_imgs] #storing unpatched images\n",
        "  ovrlp_krnl_label[num_unpatched_imgs*class_index+(num_patched_imgs*num_of_classes):num_unpatched_imgs*class_index+(num_patched_imgs*num_of_classes+num_unpatched_imgs)]=test_labels_all[test_labels_all==class_index][:num_unpatched_imgs] #storing unpatched labels\n",
        "\n",
        "\n",
        "ovrlp_krnl_imgs_flatten=ovrlp_krnl_imgs.view(ovrlp_krnl_imgs.shape[0],-1)"
      ],
      "metadata": {
        "id": "tKArRnSPBExs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Plotting the dataset**\n",
        "class_index=9\n",
        "matplotlib_imshow(torchvision.utils.make_grid(ovrlp_krnl_imgs[num_imgs_per_class*class_index:num_imgs_per_class*class_index+num_imgs_per_class],10),True)"
      ],
      "metadata": {
        "id": "l14Cb8HGCPpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Overlap Kernel generation and plotting functions**\n",
        "\n",
        "def get_overlap_kernel(model_store,epoch_index,overlap_kernel_input):\n",
        "  node_active_per_layer = [] #stores the nodes active per layer\n",
        "  effective_weights, effective_biases = model_store[epoch_index].return_gating_functions() #eff weight and bias for a particular epoch\n",
        "  for layer_num in range(num_hidden_layers):\n",
        "    weight = effective_weights[layer_num].data.numpy()\n",
        "    bias = effective_biases[layer_num].data.numpy()\n",
        "    node_active = np.sign((overlap_kernel_input@weight.T)+bias)\n",
        "    node_active[node_active < 0] = 0\n",
        "    node_active_per_layer.append(node_active) #stores the on-off status of all the nodes for each layer (num_hidden_layersx1000xnum_of_nodes)\n",
        "\n",
        "  hidden_layer_kernels = []\n",
        "  for i in range(num_hidden_layers):\n",
        "    hidden_layer_kernels.append(np.matmul(node_active_per_layer[i],node_active_per_layer[i].T)) #kernel for each hidden layer is calculated 1000x1000 which is the number of common nodes active for two image data points for that layer\n",
        "\n",
        "  overlap_kernel = hidden_layer_kernels[0]\n",
        "  for i in range(1,num_hidden_layers):\n",
        "    overlap_kernel = np.multiply(overlap_kernel, hidden_layer_kernels[i]) #this is the overlap kernel 1000x1000 which denotes the number of paths common active for two data points\n",
        "  kernels = hidden_layer_kernels + [overlap_kernel]\n",
        "\n",
        "  return overlap_kernel\n",
        "\n",
        "def plot_heatmap(K):\n",
        "  f, axes = plt.subplots(1, 1,figsize = (8,8))\n",
        "  eigen_vals = eigh(K, eigvals_only = True)\n",
        "  K = K/np.sum(eigen_vals)*100\n",
        "  ax = sns.heatmap(K, linewidth = 0)\n",
        "  # ax = sns.heatmap(K, linewidth = 0, vmin = 0, vmax = .3)\n",
        "\n",
        "  # plt.xticks([0,100, 200, 300, 400, 500, 600, 700, 800, 900], [0,100, 200, 300, 400, 500, 600, 700, 800, 900])\n",
        "  # plt.yticks([0,100, 200, 300, 400, 500, 600, 700, 800, 900], [0,100, 200, 300, 400, 500, 600, 700, 800, 900])\n",
        "  # plt.xticks([0,95, 195, 295, 395, 495, 595, 695, 795,895, 995], [0,95, 195, 295, 395, 495, 595, 695, 795,895, 995])\n",
        "  # plt.yticks([0,95, 195, 295, 395, 495, 595, 695, 795,895, 995], [0,95, 195, 295, 395, 495, 595, 695, 795,895, 995])\n",
        "\n",
        "  plt.xticks([0,95, 190, 285, 380, 475, 570, 665, 760,855, 950], [0,95, 190, 285, 380, 475, 570, 665, 760,855, 950])\n",
        "  plt.yticks([0,95, 190, 285, 380, 475, 570, 665, 760,855, 950], [0,95, 190, 285, 380, 475, 570, 665, 760,855, 950])\n",
        "\n",
        "  ax.xaxis.tick_top()\n",
        "  ax.set_aspect('equal')\n",
        "  del ax\n",
        "  plt.show()\n",
        "  plt.clf()\n",
        "  plt.close(f)"
      ],
      "metadata": {
        "id": "WbhYemzkkbmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Plotting the Overlap Kernel**\n",
        "overlap_kernel=get_overlap_kernel(model_store,30,ovrlp_krnl_imgs_flatten)\n",
        "plot_heatmap(overlap_kernel)"
      ],
      "metadata": {
        "id": "iwMBqI8iiBG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Total paths active for 1000 datapoints**\n",
        "total_path_store=np.zeros((num_of_ovlp_imgs,len(model_store))) #stores the no of paths for all 1000 data points for all 32 epochs\n",
        "for epoch_no in range(len(model_store)):\n",
        "  overlap_kernel=get_overlap_kernel(model_store,epoch_no,ovrlp_krnl_imgs_flatten)\n",
        "  diagonal_entries = np.diag(overlap_kernel)\n",
        "  total_path_store[:,epoch_no]=diagonal_entries #1000x32\n",
        ""
      ],
      "metadata": {
        "id": "BvEL9t1_Ro2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Plot choosing randomly from each class**\n",
        "\n",
        "# Define the indices for the patched images\n",
        "class_indices_patched = [[0, 94], [95, 189], [190, 284], [285, 379], [380, 474],\n",
        "                 [475, 569], [570, 664], [665, 759], [760, 854], [855, 949]]\n",
        "\n",
        "# Select one random image from each class in the patched set\n",
        "selected_img_patched = []\n",
        "for indices in class_indices_patched:\n",
        "    start_index, end_index = indices\n",
        "    random_index = np.random.randint(start_index, end_index+1)\n",
        "    selected_img_patched.append(total_path_store[random_index])\n",
        "\n",
        "# Define the indices for the unpatched images\n",
        "class_indices_unpatched = [[950, 954], [955, 959], [960, 964], [965, 969], [970, 974],\n",
        "                      [975, 979], [980, 984], [985, 989], [990, 994], [995, 999]]\n",
        "\n",
        "# Select one random array from each class in the unpatched set\n",
        "selected_img_unpatched = []\n",
        "for indices in class_indices_unpatched:\n",
        "    start_index, end_index = indices\n",
        "    random_index = np.random.randint(start_index, end_index+1)\n",
        "    selected_img_unpatched.append(total_path_store[random_index])\n",
        "\n",
        "# Create the figure with four subplots\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "# Plot the first 5 selected imgs from the patched in the first upper subplot\n",
        "for i, img in enumerate(selected_img_patched[:5]):\n",
        "    ax1.plot(np.arange(len(model_store))**2, img, label=f'Class {i}')\n",
        "\n",
        "# Set the title and labels for the first upper subplot\n",
        "ax1.set_title('Patched class 0-4')\n",
        "ax1.set_xlabel('Epochs')\n",
        "ax1.set_ylabel('No. of paths active')\n",
        "\n",
        "# Add a legend to the first upper subplot\n",
        "ax1.legend()\n",
        "\n",
        "# Plot the remaining 5 selected arrays from the first set in the second upper subplot\n",
        "for i, img in enumerate(selected_img_patched[5:]):\n",
        "    ax2.plot(np.arange(len(model_store))**2, img, label=f'Class {i+5}')\n",
        "\n",
        "# Set the title and labels for the second upper subplot\n",
        "ax2.set_title('Patched class 5-9')\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('No. of paths active')\n",
        "\n",
        "# Add a legend to the second upper subplot\n",
        "ax2.legend()\n",
        "\n",
        "# Plot the first 5 selected imgs from the unpatched set in the first bottom subplot\n",
        "for i, img in enumerate(selected_img_unpatched[:5]):\n",
        "    ax3.plot(np.arange(len(model_store))**2, img, label=f'Class {i}')\n",
        "\n",
        "# Set the title and labels for the first bottom subplot\n",
        "ax3.set_title('Unpatched class 0-4')\n",
        "ax3.set_xlabel('Epochs')\n",
        "ax3.set_ylabel('No. of paths active')\n",
        "\n",
        "# Add a legend to the first bottom subplot\n",
        "ax3.legend()\n",
        "\n",
        "# Plot the remaining 5 selected imgs from the unpatched set in the second bottom subplot\n",
        "for i, img in enumerate(selected_img_unpatched[5:]):\n",
        "    ax4.plot(np.arange(len(model_store))**2, img, label=f'Class {i+5}')\n",
        "\n",
        "# Set the title and labels for the second bottom subplot\n",
        "ax4.set_title('Unpatched class 5-9')\n",
        "ax4.set_xlabel('Epochs')\n",
        "ax4.set_ylabel('No. of paths active')\n",
        "\n",
        "# Add a legend to the second bottom subplot\n",
        "ax4.legend()\n",
        "\n",
        "# Adjust the spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tnDbv8xMY0Fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Plot mean and sdv for each class**\n",
        "\n",
        "# Define the indices for the patched images\n",
        "class_indices_patched = [[0, 94], [95, 189], [190, 284], [285, 379], [380, 474],\n",
        "                 [475, 569], [570, 664], [665, 759], [760, 854], [855, 949]]\n",
        "\n",
        "# Calculate the mean and standard deviation for each class in the patched set\n",
        "means_patched = []\n",
        "stds_patched = []\n",
        "for indices in class_indices_patched:\n",
        "    start_index, end_index = indices\n",
        "    class_patch = total_path_store[start_index:end_index+1]\n",
        "    means_patched.append(np.mean(class_patch, axis=0))\n",
        "    stds_patched.append(np.std(class_patch, axis=0))\n",
        "\n",
        "# Define the indices for the unpatched images\n",
        "class_indices_unpatched = [[950, 954], [955, 959], [960, 964], [965, 969], [970, 974],\n",
        "                      [975, 979], [980, 984], [985, 989], [990, 994], [995, 999]]\n",
        "\n",
        "# Calculate the mean and standard deviation for each class in the unpatched set\n",
        "means_unpatched = []\n",
        "stds_unpatched = []\n",
        "for indices in class_indices_unpatched:\n",
        "    start_index, end_index = indices\n",
        "    class_unpatched = total_path_store[start_index:end_index+1]\n",
        "    means_unpatched.append(np.mean(class_unpatched, axis=0))\n",
        "    stds_unpatched.append(np.std(class_unpatched, axis=0))\n",
        "\n",
        "# Create the figure with four subplots\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "# Plot the mean values for each class in the Patced set in the first upper subplot\n",
        "for i, mean_patched in enumerate(means_patched[:5]):\n",
        "    ax1.plot(np.arange(len(model_store))**2, mean_patched, label=f'Class {i}')\n",
        "\n",
        "\n",
        "# Set the title and labels for the first upper subplot\n",
        "ax1.set_title('Patched class 0-4')\n",
        "ax1.set_xlabel('Epochs')\n",
        "ax1.set_ylabel('Mean No. of paths active')\n",
        "\n",
        "# Add a legend to the first upper subplot\n",
        "ax1.legend()\n",
        "\n",
        "# Plot the mean values for each class in the first Patched in the second upper subplot\n",
        "for i, mean_patched in enumerate(means_patched[5:]):\n",
        "    ax2.plot(np.arange(len(model_store))**2, mean_patched, label=f'Class {i+5}')\n",
        "\n",
        "# Set the title and labels for the second upper subplot\n",
        "ax2.set_title('Patched class 5-9')\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Mean No. of paths active')\n",
        "\n",
        "# Add a legend to the second upper subplot\n",
        "ax2.legend()\n",
        "\n",
        "# Plot the mean values for each class in the Unpatched set in the first bottom subplot\n",
        "for i, mean_unpatched in enumerate(means_unpatched[:5]):\n",
        "    ax3.plot(np.arange(len(model_store))**2, mean_unpatched, label=f'Class {i}')\n",
        "\n",
        "# Set the title and labels for the first bottom subplot\n",
        "ax3.set_title('Unpatched class 0-4')\n",
        "ax3.set_xlabel('Epochs')\n",
        "ax3.set_ylabel('Mean No. of paths active')\n",
        "\n",
        "# Add a legend to the first bottom subplot\n",
        "ax3.legend()\n",
        "\n",
        "# Plot the mean values for each class in the Unpatched set in the second bottom subplot\n",
        "for i, mean_unpatched in enumerate(means_unpatched[5:]):\n",
        "    ax4.plot(np.arange(len(model_store))**2, mean_unpatched, label=f'Class {i+5}')\n",
        "\n",
        "# Set the title and labels for the second bottom subplot\n",
        "ax4.set_title('Unpatched class 5-9')\n",
        "ax4.set_xlabel('Epochs')\n",
        "ax4.set_ylabel('Mean No. of paths active')\n",
        "\n",
        "# Add a legend to the second bottom subplot\n",
        "ax4.legend()\n",
        "\n",
        "# Adjust the spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Create the figure with four subplots for standard deviation\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "# Plot the standard deviation values for each class in the Patched set in the first upper subplot\n",
        "for i, std_patched in enumerate(stds_patched[:5]):\n",
        "    ax1.plot(np.arange(len(model_store))**2, std_patched, label=f'Class {i}')\n",
        "\n",
        "# Set the title and labels for the first upper subplot\n",
        "ax1.set_title('Patched class 0-4')\n",
        "ax1.set_xlabel('Epochs')\n",
        "ax1.set_ylabel('Stdv No. of paths active')\n",
        "\n",
        "# Add a legend to the first upper subplot\n",
        "ax1.legend()\n",
        "\n",
        "# Plot the standard deviation values for each class in the Patched set in the second upper subplot\n",
        "for i, std_patched in enumerate(stds_patched[5:]):\n",
        "    ax2.plot(np.arange(len(model_store))**2, std_patched, label=f'Class {i+5}')\n",
        "\n",
        "# Set the title and labels for the second upper subplot\n",
        "ax2.set_title('Patched class 5-9')\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Stdv No. of paths active')\n",
        "\n",
        "# Add a legend to the second upper subplot\n",
        "ax2.legend()\n",
        "\n",
        "# Plot the standard deviation values for each class in the Unpatched set in the first bottom subplot\n",
        "for i, std_unpatched in enumerate(stds_unpatched[:5]):\n",
        "    ax3.plot(np.arange(len(model_store))**2, std_unpatched, label=f'Class {i}')\n",
        "\n",
        "# Set the title and labels for the first bottom subplot\n",
        "ax3.set_title('Unpatched class 0-4')\n",
        "ax3.set_xlabel('Epochs')\n",
        "ax3.set_ylabel('Stdv No. of paths active')\n",
        "\n",
        "# Add a legend to the first bottom subplot\n",
        "ax3.legend()\n",
        "\n",
        "# Plot the standard deviation values for each class in the Unpatched set in the second bottom subplot\n",
        "for i, std_unpatched in enumerate(stds_unpatched[5:]):\n",
        "    ax4.plot(np.arange(len(model_store))**2, std_unpatched, label=f'Class {i+5}')\n",
        "\n",
        "# Set the title and labels for the second bottom subplot\n",
        "ax4.set_title('Unpatched class 5-9')\n",
        "ax4.set_xlabel('Epochs')\n",
        "ax4.set_ylabel('Stdv No. of paths active')\n",
        "\n",
        "# Add a legend to the second bottom subplot\n",
        "ax4.legend()\n",
        "\n",
        "# Adjust the spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EeQgetntdVsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hyperplane Clustering**"
      ],
      "metadata": {
        "id": "6ZiUsu16mK_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cluster_inertia_per_epoch(model_store,epoch_index,k_min,k_max,scaled,stacked):\n",
        "  effective_weights, effective_biases = model_store[epoch_index].return_gating_functions() #eff weight and bias for a particular epoch\n",
        "  # Specify a range of possible cluster numbers\n",
        "  k_values = range(k_min, k_max)  # Change the range as per your requirements\n",
        "  inertias_per_layer=[]\n",
        "  stacked_weights=[]\n",
        "\n",
        "  for layer_num in range(num_hidden_layers):\n",
        "    weight = effective_weights[layer_num].data.numpy()\n",
        "    bias = effective_biases[layer_num].data.numpy()\n",
        "    appended_weight = np.hstack((weight, bias.reshape(bias.shape[0], 1)))\n",
        "\n",
        "    if stacked:\n",
        "      stacked_weights.append(appended_weight)\n",
        "\n",
        "\n",
        "    else:\n",
        "      # Perform l2 norm scaling on the data\n",
        "      if scaled:\n",
        "        l2_norms = np.linalg.norm(appended_weight, axis=1)\n",
        "        scaled_appended_weight = appended_weight / l2_norms[:, np.newaxis]\n",
        "      else:\n",
        "        scaled_appended_weight=appended_weight\n",
        "\n",
        "      # Initialize an empty list to store the inertia values\n",
        "      inertias = []\n",
        "\n",
        "      # Iterate over different cluster numbers and calculate inertia\n",
        "      for k in k_values:\n",
        "        kmeans = KMeans(n_clusters=k,n_init=10, random_state=0)\n",
        "        kmeans.fit(scaled_appended_weight)\n",
        "        inertia = kmeans.inertia_\n",
        "        inertias.append(inertia)\n",
        "      inertias_per_layer.append(inertias)\n",
        "\n",
        "  if stacked:\n",
        "    combined_weights = np.vstack((stacked_weights[0], stacked_weights[1]))\n",
        "    for i in range(2, num_hidden_layers):\n",
        "      combined_weights = np.vstack((combined_weights,stacked_weights[i]))\n",
        "\n",
        "    # Verify the shape of the combined array\n",
        "\n",
        "    if scaled:\n",
        "      l2_norms = np.linalg.norm(combined_weights, axis=1)\n",
        "      scaled_appended_weight = combined_weights / l2_norms[:, np.newaxis]\n",
        "      # Calculate the element-wise square\n",
        "      # for i in range(300): #to check if vector is l2_normalized\n",
        "      #   squared_vector = np.square(scaled_appended_weight[i])\n",
        "\n",
        "      #   # Sum the squared values\n",
        "      #   sum_of_squares = np.sum(squared_vector)\n",
        "\n",
        "      #   print(\"Sum of Squares:\", sum_of_squares)\n",
        "    else:\n",
        "      scaled_appended_weight=combined_weights\n",
        "\n",
        "    # Initialize an empty list to store the inertia values\n",
        "    inertias = []\n",
        "\n",
        "    # Iterate over different cluster numbers and calculate inertia\n",
        "    for k in k_values:\n",
        "      kmeans = KMeans(n_clusters=k,n_init=10, random_state=0)\n",
        "      kmeans.fit(scaled_appended_weight)\n",
        "      inertia = kmeans.inertia_\n",
        "      inertias.append(inertia)\n",
        "    return k_values,inertias\n",
        "\n",
        "  return k_values,inertias_per_layer\n",
        "    # # Get the cluster labels and centroids\n",
        "    # cluster_labels = kmeans.labels_\n",
        "    # centroids = kmeans.cluster_centers_\n",
        "    # # Get the inertia of the clustering solution\n",
        "    # inertia = kmeans.inertia_"
      ],
      "metadata": {
        "id": "wzluDsf5mY_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_min=1\n",
        "k_max=3\n",
        "scaled = True\n",
        "stacked = False\n",
        "k_values_store=[]\n",
        "inertias_per_layer_store=[]\n",
        "epoch_index_store=[]\n",
        "for epoch_index in range(len(model_store)):\n",
        "  if(perfectSq(epoch_index) or epoch_index==len(model_store)-1):\n",
        "    k_values,inertias_per_layer=get_cluster_inertia_per_epoch(model_store,epoch_index,k_min,k_max,scaled,stacked)\n",
        "    k_values_store.append(k_values)\n",
        "    inertias_per_layer_store.append(inertias_per_layer)\n",
        "    epoch_index_store.append(epoch_index)"
      ],
      "metadata": {
        "id": "3tkK-0aB8yko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the inertia values\n",
        "if stacked:\n",
        "  for index,epoch in enumerate(epoch_index_store):\n",
        "    plt.plot(k_values_store[index], inertias_per_layer_store[index],label='Epoch:'+str(epoch**2))\n",
        "  plt.xlabel('Number of Clusters (k)')\n",
        "  plt.ylabel('Inertia')\n",
        "  plt.legend()\n",
        "  plt.title('Inertia vs. Number of Clusters for stacked layer')\n",
        "  plt.show()\n",
        "else:\n",
        "  for layer_num in range(num_hidden_layers):\n",
        "    for index,epoch in enumerate(epoch_index_store):\n",
        "      plt.plot(k_values_store[index], inertias_per_layer_store[index][layer_num],label='Epoch:'+str(epoch**2))\n",
        "    plt.xlabel('Number of Clusters (k)')\n",
        "    plt.ylabel('Inertia')\n",
        "    plt.legend()\n",
        "    plt.title('Inertia vs. Number of Clusters for layer:'+str(layer_num))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Y6lLkjrC4nGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rough**"
      ],
      "metadata": {
        "id": "aThQppDQBRGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class MyModule(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.linears = nn.ModuleList([nn.Linear(2, 2) for i in range(2)])\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # ModuleList can act as an iterable, or be indexed using ints\n",
        "#         for i, l in enumerate(self.linears):\n",
        "#             x = self.linears[i // 2](x) + l(x)\n",
        "#         return x\n"
      ],
      "metadata": {
        "id": "oR-zEVZqKAJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mymodule = MyModule().to(device)"
      ],
      "metadata": {
        "id": "QybpgTfUm8JN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for params in mymodule.named_parameters():\n",
        "#   print(params)"
      ],
      "metadata": {
        "id": "DMUn2QT7nAGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "# =============================================================================\n",
        "# Import\n",
        "# =============================================================================\n",
        "\n",
        "import torch         # PyTorch\n",
        "from torch import nn # needed for training neural network (nn)\n",
        "from tqdm import tqdm\n",
        "# TorchVision contains FashionMNIST dataset\n",
        "from torchvision import datasets\n",
        "\n",
        "# DataLoader wraps an iterable around the Dataset - convenient!\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# following needed for converting data to tensors\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# lastly, Numpy & Matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# =============================================================================\n",
        "# FashionMNIST 👚👗 Training & Test datasets\n",
        "# =============================================================================\n",
        "\n",
        "# download Training data\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root      = \"data\",\n",
        "    train     = True,       # for Training data\n",
        "    download  = True,\n",
        "    transform = ToTensor()  # for converting to tensor\n",
        "    )\n",
        "\n",
        "# quick check\n",
        "train_data            # 60K training samples\n",
        "train_data.data.shape # each sample is 28x28 grayscale image\n",
        "np.unique(train_data.targets, return_counts = True)\n",
        "# 10 unique labels: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "# each label appearing 6K times\n",
        "\n",
        "\n",
        "\n",
        "# download Test data\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root      = \"data\",\n",
        "    train     = False,      # for Test data\n",
        "    download  = True,\n",
        "    transform = ToTensor()  # for converting to tensor\n",
        "    )\n",
        "\n",
        "\n",
        "# quick check\n",
        "test_data             # 10K test samples\n",
        "test_data.data.shape  # each sample is 28x28 grayscale image\n",
        "np.unique(test_data.targets, return_counts = True)\n",
        "# 10 unique labels: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "# each label appearing 1K times\n",
        "\n",
        "# =============================================================================\n",
        "# DataLoader\n",
        "# =============================================================================\n",
        "\n",
        "# create DataLoader for Training data with batch size 64\n",
        "train_dataloader = DataLoader(dataset    = train_data,\n",
        "                              batch_size = 64)\n",
        "\n",
        "# create DataLoader for Test data     with batch size 64\n",
        "test_dataloader = DataLoader(dataset    = test_data,\n",
        "                             batch_size = 64)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # let's understand our DataLoader...\n",
        "\n",
        "# # we can still see 60K Training samples like this\n",
        "# train_dataloader.dataset      # 60K datapoints\n",
        "# len(train_dataloader.dataset) # 60K\n",
        "\n",
        "# # 🚨 BUT the dataloader ITSELF is a bit DIFFERENT\n",
        "# len(train_dataloader) # 938 (as OPPOSED to 60K)\n",
        "\n",
        "# # remember we set our batch size to 64 (`batch_size = 64`) above\n",
        "# # if we multiply 64 by 938\n",
        "# 938 * 64 # 60032            <-- which is roughly 60K 🔥\n",
        "# # so DataLoader has divided 60K into 938 \"groups\"\n",
        "\n",
        "# # let's check 938 \"groups\"\n",
        "# for batch, (x, y) in enumerate(train_dataloader):\n",
        "#     print(batch + 1)    # +1 since it starts from 0\n",
        "#     print(f\"shape of x: {x.shape}\")\n",
        "#     print(f\"shape of y: {y.shape} & dtype of y: {y.dtype}\")\n",
        "# # notice the last batch is 938\n",
        "\n",
        "\n",
        "# # few more checks by me (not video) --------------\n",
        "# for batch, (x, y) in enumerate(train_dataloader):\n",
        "#     print(batch + 1)\n",
        "#     print(f\"{x.shape}\")   # [64, 1, 28, 28]\n",
        "#     print(f\"{y}\")\n",
        "#     break\n",
        "\n",
        "# for batch, (x, y) in enumerate(train_dataloader):\n",
        "#     print(batch + 1)\n",
        "#     print(f\"{x}\")\n",
        "#     print(f\"{y}\")\n",
        "#     break\n",
        "\n",
        "# for x, y in train_dataloader:\n",
        "#     print(f\"{x.shape}\")\n",
        "#     print(f\"{y}\")\n",
        "#     break\n",
        "\n",
        "# for x, y in train_data:\n",
        "#     print(f\"{x.shape}\")\n",
        "#     print(f\"{y}\")\n",
        "#     break\n",
        "# for i in test_data:\n",
        "#     print(i)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Create Neural Network model 🚀\n",
        "# =============================================================================\n",
        "\n",
        "# According to the Link I am referring to:\n",
        "#     \"To define a Neural Network in PyTorch, we create a class that inherits\n",
        "#     from nn.Module.\"\n",
        "\n",
        "\n",
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module): # inherit from nn.Module\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        # define the layers of the network in the __init__ function\n",
        "\n",
        "        super().__init__()     # super() to inherit methods from nn.Module\n",
        "\n",
        "        # Flattening\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # Architecture\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(in_features  = 28*28, # apply linear transformation\n",
        "                      out_features = 10),\n",
        "            nn.ReLU(),                      # apply rectified linear unit\n",
        "            nn.Linear(in_features  = 10,   #       linear transformation\n",
        "                      out_features = 10),\n",
        "            nn.ReLU(),                      #       rectified linear unit\n",
        "            nn.Linear(in_features  = 10,   #       linear transformation\n",
        "                      out_features = 10)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # specify how data pass through the network in the forward function\n",
        "        # using self.flatten() & self.linear_relu_stack() from __init__\n",
        "\n",
        "\n",
        "        # flattening to get the correct in_features\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        # Stacking Linear ReLU layers\n",
        "        network = self.linear_relu_stack(x)\n",
        "        return network\n",
        "\n",
        "\n",
        "# check architecture\n",
        "simpleNN = NeuralNetwork().to(device)\n",
        "# notice flatten & linear_relu_stack created from above\n",
        "print(simpleNN)\n",
        "\n",
        "# del simpleNN\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Loss Function & Optimizer\n",
        "# =============================================================================\n",
        "\n",
        "# Loss\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "# use CrossEntropy since this is 10-label classification problem\n",
        "\n",
        "# Optimizer\n",
        "opt = torch.optim.SGD(              # stochastic gradient descent\n",
        "    params = simpleNN.parameters(), # simpleNN parameters to optimize\n",
        "    lr     = 1e-3                   # learning rate\n",
        "    )\n",
        "\n",
        "# =============================================================================\n",
        "# Training function    -  backpropagates prediction error\n",
        "# =============================================================================\n",
        "\n",
        "def training(dataloader, model, loss_func, optimizer):\n",
        "    # train simpleNN, while monitoring Loss\n",
        "\n",
        "    size = len(dataloader.dataset) # 60K since there are 60K Training samples\n",
        "\n",
        "    # Sets the module in training mode\n",
        "    model.train()\n",
        "\n",
        "    for batch, (x, y) in tqdm(enumerate(dataloader)): # training 1 batch at a time\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        # Compute loss\n",
        "        pred = model(x)           # simpleNN prediction\n",
        "        loss = loss_func(pred, y) # Loss calculation\n",
        "\n",
        "\n",
        "        # Backpropagation to adjust model's parameters\n",
        "        optimizer.zero_grad() # zero out gradients in each loop\n",
        "        loss.backward()       # computes gradient in reverse direction\n",
        "        optimizer.step()      # conduct a single optimization step\n",
        "\n",
        "\n",
        "        # Monitor for decrease in Loss as training progresses\n",
        "        if batch % 100 == 0:\n",
        "            loss    = loss.item()     # Loss\n",
        "            current = batch * len(x)  # Progress\n",
        "            print(f\"loss: {loss:>5f} at {current:>5d}/{size:>5d}\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Test function   -  evaluate model against Test data\n",
        "# =============================================================================\n",
        "\n",
        "def testing(dataloader, model, loss_func):\n",
        "    # Evaluate simpleNN with Test data at the end of each epoch by\n",
        "    # monitoring the changes in Accuracy & Loss\n",
        "\n",
        "    size = len(dataloader.dataset) # 10K, since there are 10K test samples\n",
        "    num_batch = len(dataloader)    # 157 = len(test_dataloader)\n",
        "\n",
        "    # sets the module in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # initialize monitoring values (starting from 0)\n",
        "    test_loss, correct  = 0, 0\n",
        "\n",
        "    with torch.no_grad(): # no_grad() to disable gradient calculation\n",
        "        for x, y in dataloader:\n",
        "            # prediction with simpleNN\n",
        "            pred       = model(x)\n",
        "\n",
        "            # accumulate Loss and number of correct prediction\n",
        "            test_loss += loss_func(pred, y).item()\n",
        "            correct   += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "\n",
        "    # updated monitoring value\n",
        "    test_loss /= num_batch  # Average Loss\n",
        "    correct   /= size       # Accuracy\n",
        "\n",
        "    print(f\"\\n Test Evaluation: \\n Accuracy: {(100*correct):>5f}%,\\\n",
        "    Avg loss: {test_loss:>5f} \\n\")\n",
        "\n",
        "# =============================================================================\n",
        "# Train & Evaluation\n",
        "# =============================================================================\n",
        "\n",
        "# use training() & testing() functions we just defined earlier\n",
        "\n",
        "\n",
        "\n",
        "# number of epochs\n",
        "epochs = 10\n",
        "\n",
        "# train model & evaluate\n",
        "for t in range(epochs):\n",
        "    print(f\"\\n\\n   Epoch {t+1}  -------------------- \\n\")\n",
        "\n",
        "    # training\n",
        "    training(train_dataloader, simpleNN, loss_func, opt)\n",
        "\n",
        "    # testing\n",
        "    # testing(test_dataloader, simpleNN, loss_func)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "53SnIXZTnHSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10 nodes 2L relu --> 10 epochs gpu = 1m30s\n",
        "#10 nodes 2L relu --> 10 epochs cpu = 2m05s\n",
        "\n",
        "#10 nodes 2L dlgn --> 10 epochs gpu = 3m00s\n",
        "#10 nodes 2L dlgn --> 10 epochs cpu = 3m30s"
      ],
      "metadata": {
        "id": "VRsbPsDJSlzg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
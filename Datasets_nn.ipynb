{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5RelxeYr/KbrQK4bQgPCD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Doeschate/Research/blob/main/Datasets_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e882qhR-PovW"
      },
      "outputs": [],
      "source": [
        "#@title Install NAM from github AND <font color='red'>**RESTART colab after install**</font>\n",
        "# https://stackoverflow.com/questions/13566200/how-can-i-install-from-a-git-subdirectory-with-pip\n",
        "!pip3 install -U --verbose -e \"git+https://github.com/agarwl/google-research.git#egg=neural_additive_models&subdirectory=neural_additive_models\" # install a python package from a repo subdirectory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import random\n",
        "random.seed(365)\n",
        "\n",
        "import data_utils\n",
        "import models as nam_models\n",
        "import graph_builder\n",
        "import os.path as osp\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "yMlllDCEpxLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "3CbCqceJBzw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dataset helpers\n",
        "\n",
        "def load_col_min_max(dataset_name):\n",
        "  \"\"\"Loads the dataset according to the `dataset_name` passed.\"\"\"\n",
        "  if dataset_name == 'Housing': ##\n",
        "    dataset = data_utils.load_california_housing_data()\n",
        "  elif dataset_name == 'BreastCancer':\n",
        "    dataset = data_utils.load_breast_data()\n",
        "  elif dataset_name == 'Recidivism':\n",
        "    dataset = data_utils.load_recidivism_data()\n",
        "  elif dataset_name == 'Fico': ##\n",
        "    dataset = data_utils.load_fico_score_data()\n",
        "  elif dataset_name == 'Mimic2': ##\n",
        "    dataset = load_mimic2_data()\n",
        "  elif dataset_name == 'Credit':\n",
        "    dataset = data_utils.load_credit_data()\n",
        "  else:\n",
        "    raise ValueError('{} not found!'.format(dataset_name))\n",
        "\n",
        "  if 'full' in dataset:\n",
        "    dataset = dataset['full']\n",
        "  x = dataset['X']\n",
        "  col_min_max = {}\n",
        "  for col in x:\n",
        "    unique_vals = x[col].unique()\n",
        "    col_min_max[col] = (np.min(unique_vals), np.max(unique_vals))\n",
        "  return col_min_max\n",
        "\n",
        "def inverse_min_max_scaler(x, min_val, max_val):\n",
        "  return (x + 1)/2 * (max_val - min_val) + min_val "
      ],
      "metadata": {
        "id": "-rruyL5Vp2B8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load dataset\n",
        "#BreastCancer/Recidivism/Credit\n",
        "dataset_name = 'BreastCancer' #@param {'type': 'string'}\n",
        "is_regression = dataset_name in ['Housing', 'Fico']\n",
        "data =  data_utils.load_dataset(dataset_name)\n",
        "data_x, data_y, column_names = data\n",
        "col_min_max = load_col_min_max(dataset_name)"
      ],
      "metadata": {
        "id": "ytLcZex4qZZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB04uIiZluVC",
        "outputId": "1c1c27c6-e264-46d6-f0f6-80d509df1eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "569"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create train/test split\n",
        "\n",
        "(x_train_all, y_train_all), (x_test_all, y_test_all) = data_utils.get_train_test_fold(\n",
        "      data_x, data_y, fold_num=1, num_folds=5, stratified=not is_regression)\n",
        "\n",
        "\n",
        "# data_gen = data_utils.split_training_dataset(\n",
        "#       x_train_all, y_train_all, \n",
        "#       n_splits=20, stratified=not is_regression)\n",
        "\n",
        "\n",
        "# (x_train, y_train), _ = next(data_gen)"
      ],
      "metadata": {
        "id": "hcjSPMqxvMCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(y_test_all))\n",
        "print(len(y_train_all))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWZ3ynkVoKvC",
        "outputId": "92ab8a1d-468f-4ecf-a84a-91a296103693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "114\n",
            "455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Custom Dataset\n",
        "class CustomDataset:\n",
        "  def __init__(self,data,targets):\n",
        "    self.data = data\n",
        "    self.targets = targets\n",
        "  def __len__(self):\n",
        "    return self.data.shape[0]\n",
        "  def __getitem__(self,idx):\n",
        "    current_sample = self.data[idx,:]\n",
        "    current_target = self.targets[idx]\n",
        "    return {\n",
        "        \"x\": torch.tensor(current_sample,dtype=torch.float),\n",
        "        \"y\": torch.tensor(current_target,dtype=torch.long),\n",
        "    }"
      ],
      "metadata": {
        "id": "Kj_Zq_Dc162h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(data=x_train_all, targets= y_train_all)\n",
        "test_dataset = CustomDataset(data=x_test_all, targets= y_test_all)"
      ],
      "metadata": {
        "id": "isQnJ8Ff5E8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[5][\"x\"].shape[0])\n",
        "print(train_dataset[5][\"y\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiFvjPgW6dZx",
        "outputId": "9a699fc9-a2eb-4b47-a550-bd6995f53d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n",
            "tensor(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Parameters\n",
        "#LinearModel/nlModel/dnnModel\n",
        "model_name = 'LinearModel' #@param {'type': 'string'}\n",
        "batch_size = 4\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "optimizer_name ='SGD'\n",
        "input_size=train_dataset[0][\"x\"].shape[0]\n",
        "output_size=2"
      ],
      "metadata": {
        "id": "0aw3Xyh7_njh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearModel(nn.Module):\n",
        "  def __init__(self,input_size,output_size):\n",
        "    super(LinearModel, self).__init__()\n",
        "    print(\"LinearModel\")\n",
        "    self.ll1 = nn.Linear(input_size,10)\n",
        "    self.ll2 = nn.Linear(10,output_size)\n",
        "  def forward(self,inputs):\n",
        "    x = self.ll1(inputs)\n",
        "    x = self.ll2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "HaP2NJQTBNNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NTK\n",
        "#install JAX on CPU by running\n",
        "!pip install jax jaxlib --upgrade\n",
        "#Once JAX is installed install Neural Tangents by running\n",
        "!pip install neural-tangents"
      ],
      "metadata": {
        "id": "RjRq_pIkgdsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "djNztl4FkCHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class nlModel(nn.Module):\n",
        "  def __init__(self,input_size,output_size):\n",
        "    super(nlModel, self).__init__()\n",
        "    print(\"nlModel\")\n",
        "    self.nl1 = nn.Linear(input_size,10)\n",
        "    self.nl2 = nn.Linear(10,output_size)\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    x = F.relu(self.nl1(inputs))\n",
        "    x = self.nl2(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "btztsQDQNoA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class dnnModel(nn.Module):\n",
        "  def __init__(self,input_size,output_size):\n",
        "    super(dnnModel, self).__init__()\n",
        "    print(\"dnnModel\")\n",
        "    self.nl1 = nn.Linear(input_size,10)\n",
        "    self.nl2 = nn.Linear(10,10)\n",
        "    self.nl3 = nn.Linear(10,10)\n",
        "    self.nl4 = nn.Linear(10,output_size)\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    x = F.relu(self.nl1(inputs))\n",
        "    x = F.relu(self.nl2(x))\n",
        "    x = F.relu(self.nl3(x))\n",
        "    x = self.nl4(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "uwjm9EqNEP4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if model_name == 'nlModel':\n",
        "  model = nlModel(input_size,output_size).to(device)\n",
        "if model_name == 'LinearModel':\n",
        "  model = LinearModel(input_size,output_size).to(device) \n",
        "if model_name == 'dnnModel':\n",
        "  model = dnnModel(input_size,output_size).to(device) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68hHhPKfF4o3",
        "outputId": "67be20f1-b70d-4435-874d-ceaed466cffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearModel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "if optimizer_name == 'SGD':\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "if optimizer_name == 'Adam':\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "O6nWpr8ICNnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train Dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=False)\n"
      ],
      "metadata": {
        "id": "e5ge1IrN-4gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  i=0\n",
        "  for train_data in train_loader:\n",
        "    i=i+1\n",
        "    xtrain=train_data[\"x\"]\n",
        "    ytrain=train_data[\"y\"]\n",
        "    xtrain = xtrain.to(device)\n",
        "    ytrain = ytrain.to(device)\n",
        "   \n",
        "    # Forward pass\n",
        "    outputs = model(xtrain)\n",
        "    loss = criterion(outputs, ytrain)\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    # Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1) % 100 == 0:\n",
        "      print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnphXGGpAt_j",
        "outputId": "a24c0173-45c8-4eb5-a6fb-9b3ba83f84ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/114], Loss: 0.5546\n",
            "Epoch [2/10], Step [100/114], Loss: 0.6843\n",
            "Epoch [3/10], Step [100/114], Loss: 0.4200\n",
            "Epoch [4/10], Step [100/114], Loss: 0.3658\n",
            "Epoch [5/10], Step [100/114], Loss: 0.6214\n",
            "Epoch [6/10], Step [100/114], Loss: 0.6052\n",
            "Epoch [7/10], Step [100/114], Loss: 0.6496\n",
            "Epoch [8/10], Step [100/114], Loss: 0.4376\n",
            "Epoch [9/10], Step [100/114], Loss: 0.5316\n",
            "Epoch [10/10], Step [100/114], Loss: 0.2766\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = []\n",
        "labels = []\n",
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  for test_data in test_loader:\n",
        "    xtest=test_data[\"x\"]\n",
        "    ytest=test_data[\"y\"]\n",
        "    xtest = xtest.to(device)\n",
        "    ytest = ytest.to(device)\n",
        "\n",
        "    output = model(xtest)\n",
        "    labels.append(ytest)\n",
        "\n",
        "    # max returns (value ,index)\n",
        "    _, predicted = torch.max(output, 1)\n",
        "    outputs.append(predicted)\n",
        "\n",
        "    n_samples += ytest.size(0)\n",
        "    n_correct += (predicted == ytest).sum().item()\n",
        "  acc = 100.0 * n_correct / n_samples\n",
        "  print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWsw4eS9R6I3",
        "outputId": "61b3a6bc-e6af-463b-9975-c17b401b1633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network: 67.54385964912281 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import jax.numpy as np\n",
        "# import neural_tangents as nt\n",
        "# from neural_tangents import stax\n",
        "# init_fn, apply_fn, kernel_fn = stax.serial(\n",
        "#     stax.Dense(10), stax.Relu(),\n",
        "#     stax.Dense(10), stax.Relu(),\n",
        "#     stax.Dense(1)\n",
        "# )\n",
        "\n",
        "# x_train = xtrain\n",
        "# x_test = xtest\n",
        "# y_train = ytrain\n",
        "# y_test = ytest\n",
        "# kernel = kernel_fn(x_train, x_test, 'ntk')\n",
        " \n",
        "\n",
        "# ntk_train_train = kernel_fn(x_train, None, 'ntk')\n",
        "\n",
        "# ntk_test_train = kernel_fn(x_test, x_train, 'ntk')\n",
        "\n",
        "# mse_predictor = nt.predict.gradient_descent_mse(ntk_train_train, y_train)\n",
        "\n",
        "# # t = 5.\n",
        "# y_test_ntk = mse_predictor(x_test=x_test, get='ntk')\n",
        "# # y_train_t, y_test_t = mse_predictor(t, y_train_0, y_test_0, ntk_test_train)\n"
      ],
      "metadata": {
        "id": "n56a0BK81S2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(labels))\n",
        "print(len(outputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruUnjHrW0grW",
        "outputId": "922a136a-c5ab-438f-d2f0-55b0942b78dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29\n",
            "29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.roc_auc_score(torch.cat(labels).view(-1),torch.cat(outputs).view(-1))"
      ],
      "metadata": {
        "id": "0hkmLwpfC7fM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc5dbbb-1d78-4576-a21f-476d8515ac04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6395348837209303"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sum(torch.cat(labels).view(-1)))\n",
        "print(sum(torch.cat(outputs).view(-1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LFKzfou5lMf",
        "outputId": "c5a3b0c9-b9e5-4ec5-de37-0e5568dd3074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(71)\n",
            "tensor(102)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Results\n",
        "\n",
        "##CREDIT DATASET\n",
        "model_name = 'LinearModel' \n",
        "batch_size = 32\n",
        "num_epochs = 5\n",
        "learning_rate = 0.001\n",
        "optimizer_name ='SGD'\n",
        "input_size=train_dataset[0][\"x\"].shape[0]\n",
        "output_size=2\n",
        "#Accuracy of the network: 99.82619992275552 %\n",
        "#roc_auc_score: 0.5\n",
        "\n",
        "model_name = 'nlModel' \n",
        "batch_size = 32\n",
        "num_epochs = 5\n",
        "learning_rate = 0.001\n",
        "optimizer_name ='SGD'\n",
        "input_size=train_dataset[0][\"x\"].shape[0]\n",
        "output_size=2\n",
        "#Accuracy of the network: 99.82619992275552 %\n",
        "#0.5\n",
        "\n",
        "model_name = 'dnnModel' \n",
        "batch_size = 32\n",
        "num_epochs = 5\n",
        "learning_rate = 0.001\n",
        "optimizer_name ='SGD'\n",
        "input_size=train_dataset[0][\"x\"].shape[0]\n",
        "output_size=2\n",
        "#Accuracy of the network: 99.82619992275552 %\n",
        "#0.5\n",
        "\n",
        "##Recidivism\n",
        "model_name = 'LinearModel' \n",
        "batch_size = 4\n",
        "num_epochs = 10\n",
        "learning_rate = 0.0001\n",
        "optimizer_name ='SGD'\n",
        "input_size=train_dataset[0][\"x\"].shape[0]\n",
        "output_size=2\n",
        "#Accuracy of the network: 60.5668016194332 %\n",
        "#roc_auc_score: 0.5717150592502894\n",
        "\n",
        "model_name = 'nlModel' \n",
        "batch_size = 4\n",
        "num_epochs = 10\n",
        "learning_rate = 0.0001\n",
        "optimizer_name ='SGD'\n",
        "input_size=train_dataset[0][\"x\"].shape[0]\n",
        "output_size=2\n",
        "#Accuracy of the network: 54.412955465587046 %\n",
        "#roc_auc_score: 0.49925705794947994\n",
        "\n",
        "model_name = 'dnnModel' \n",
        "batch_size = 4\n",
        "num_epochs = 10\n",
        "learning_rate = 0.0001\n",
        "optimizer_name ='SGD'\n",
        "input_size=train_dataset[0][\"x\"].shape[0]\n",
        "output_size=2\n",
        "#Accuracy of the network: 54.493927125506076 %\n",
        "#roc_auc_score: 0.5"
      ],
      "metadata": {
        "id": "AEQZ1Zl3yVuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3jbtsypRzObe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}